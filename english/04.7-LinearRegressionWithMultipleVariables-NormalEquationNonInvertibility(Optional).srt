1
00:00:00,170 --> 00:00:01,190
In this video, I want to

2
00:00:01,200 --> 00:00:04,740
talk about the normal equation and non-invertibility.

3
00:00:05,040 --> 00:00:06,440
This is a somewhat more

4
00:00:06,450 --> 00:00:07,650
advanced concept but there

5
00:00:07,660 --> 00:00:09,540
is something to often been asked

6
00:00:09,550 --> 00:00:12,420
about and, so, I want to talk about here, and answer it here.

7
00:00:12,430 --> 00:00:13,380
But, this is a somewhat more

8
00:00:13,390 --> 00:00:15,600
advanced concept, so, feel free

9
00:00:15,610 --> 00:00:18,350
to consider this optional material

10
00:00:18,530 --> 00:00:20,390
and There's a phenomenon that

11
00:00:20,400 --> 00:00:22,040
you may have run into that

12
00:00:22,050 --> 00:00:23,970
may be, somewhat useful to understand.

13
00:00:23,980 --> 00:00:25,420
But, even if you don't understand it,

14
00:00:25,430 --> 00:00:27,270
the normal equation and linear

15
00:00:27,280 --> 00:00:30,690
regression, you should be able to get that to work okay.

16
00:00:31,290 --> 00:00:33,180
Here's the issue.

17
00:00:33,420 --> 00:00:34,520
For those of you that are,

18
00:00:34,530 --> 00:00:35,820
maybe, some are more familiar with

19
00:00:35,830 --> 00:00:37,890
linear algebra, what some

20
00:00:37,900 --> 00:00:38,960
students were asking me it

21
00:00:38,970 --> 00:00:41,460
is while computing this, theta

22
00:00:41,470 --> 00:00:44,730
goes extras cosx plus

23
00:00:44,740 --> 00:00:46,070
extras of cosy, one of them

24
00:00:46,080 --> 00:00:47,940
matrix X transpose X is non-invertible.

25
00:00:47,950 --> 00:00:50,300
So, for those of

26
00:00:50,310 --> 00:00:51,410
you that know a bit more linear

27
00:00:51,420 --> 00:00:52,910
algebra, you may know

28
00:00:52,920 --> 00:00:54,090
that, you know, only some

29
00:00:54,100 --> 00:00:56,050
matrices are invertible and

30
00:00:56,060 --> 00:00:58,100
some matrices do not have an inverse.

31
00:00:58,110 --> 00:01:01,610
We call those non-invertible matrixes, singular

32
00:01:01,620 --> 00:01:04,220
or degenerate matrixes.

33
00:01:04,230 --> 00:01:05,730
The issue or the problem

34
00:01:05,740 --> 00:01:07,290
if X transpose X being

35
00:01:07,300 --> 00:01:10,950
non invertible, should happen pretty rarely.

36
00:01:10,960 --> 00:01:12,630
And, in octave, if

37
00:01:12,640 --> 00:01:15,260
you implement this to compute

38
00:01:15,270 --> 00:01:17,070
data, it turns out

39
00:01:17,080 --> 00:01:18,530
that this would actually do

40
00:01:18,540 --> 00:01:19,700
the right thing, I am getting

41
00:01:19,710 --> 00:01:21,910
a little technical now,

42
00:01:21,920 --> 00:01:23,090
and I don't want to

43
00:01:23,100 --> 00:01:25,560
go in details, but octave has

44
00:01:25,570 --> 00:01:27,790
two functions for inverting matrices.

45
00:01:27,800 --> 00:01:29,920
One is called p (n) and

46
00:01:29,930 --> 00:01:31,620
the other is called n.  And,

47
00:01:31,630 --> 00:01:35,010
the differences between these two are somewhat technical.

48
00:01:35,020 --> 00:01:36,520
One is the pseudo inverse one

49
00:01:36,530 --> 00:01:38,250
is called the inverse that you

50
00:01:38,260 --> 00:01:40,860
can show mathematically that

51
00:01:40,870 --> 00:01:43,390
use the p (n) function then

52
00:01:43,400 --> 00:01:44,950
this world, this world can

53
00:01:44,960 --> 00:01:46,330
actually compute the value of

54
00:01:46,340 --> 00:01:50,780
data that you want even if X transverse X is noninvertable.

55
00:01:50,970 --> 00:01:52,650
The specific details between, you

56
00:01:52,660 --> 00:01:54,230
know, what is the difference between P

57
00:01:54,240 --> 00:01:56,050
(n) and what is N that's

58
00:01:56,060 --> 00:01:57,500
somewhat advanced hence the

59
00:01:57,510 --> 00:02:00,690
miracle of computing concepts, I don't really want to get into.

60
00:02:00,700 --> 00:02:01,910
But, I thought in this

61
00:02:01,920 --> 00:02:03,420
optional video I'll give, I'll

62
00:02:03,430 --> 00:02:04,450
try to give you a little bit of

63
00:02:04,460 --> 00:02:05,690
intuition about what it

64
00:02:05,700 --> 00:02:07,510
means well, extras of x

65
00:02:07,520 --> 00:02:09,060
is not invertible, those of

66
00:02:09,070 --> 00:02:10,990
you that know more

67
00:02:11,000 --> 00:02:13,070
linear might be interested,

68
00:02:13,080 --> 00:02:14,200
I'm not going to prove this

69
00:02:14,210 --> 00:02:18,320
mathematically but if X transpose X is non-invertible.

70
00:02:18,370 --> 00:02:20,050
There are usually two most

71
00:02:20,060 --> 00:02:22,120
common causes for this.

72
00:02:22,130 --> 00:02:24,230
The first cause is if somehow,

73
00:02:24,240 --> 00:02:27,660
in your learning problem, you have redundant features.

74
00:02:27,670 --> 00:02:28,860
Concretely, when you're trying

75
00:02:28,870 --> 00:02:30,740
to predict housing prices, and

76
00:02:30,750 --> 00:02:32,100
if X1 is the size of

77
00:02:32,110 --> 00:02:33,950
the housing feet, in square

78
00:02:33,960 --> 00:02:35,350
feet, and X2 is the

79
00:02:35,360 --> 00:02:36,710
size of the house in square

80
00:02:36,720 --> 00:02:38,870
meters, then, you know,

81
00:02:38,880 --> 00:02:41,570
one meter is equal to

82
00:02:41,580 --> 00:02:46,030
3.28 feet, rounded to 2 decimals.

83
00:02:46,040 --> 00:02:47,510
And so your two features will

84
00:02:47,520 --> 00:02:50,080
always satisfy the constraint that x1 equals

85
00:02:50,090 --> 00:02:54,640
3.28 square times x2.

86
00:02:54,650 --> 00:02:56,240
And you can show, for

87
00:02:56,250 --> 00:02:58,710
those of you that are just somewhat advanced in the algebra now.

88
00:02:58,720 --> 00:03:00,420
But, if you're inexperienced in the algebra,

89
00:03:00,430 --> 00:03:01,970
you can actually show that if

90
00:03:01,980 --> 00:03:03,900
your two features are related for

91
00:03:03,910 --> 00:03:05,570
a linear equation like this then

92
00:03:05,580 --> 00:03:08,750
matrix X transverse X will be non-invertable.

93
00:03:08,760 --> 00:03:09,890
The second thing that can

94
00:03:09,900 --> 00:03:12,580
cause X transverse X to be non-invertable

95
00:03:12,590 --> 00:03:14,170
is if you're training if

96
00:03:14,180 --> 00:03:15,590
you're trying to run a

97
00:03:15,600 --> 00:03:17,330
learning algorithm with a lot

98
00:03:17,340 --> 00:03:20,440
of features, concretely if M

99
00:03:20,450 --> 00:03:21,620
is less than or equal

100
00:03:21,630 --> 00:03:23,420
to N. For example, if

101
00:03:23,430 --> 00:03:25,110
you imagine that you have

102
00:03:25,120 --> 00:03:27,950
M10 training examples, that

103
00:03:27,960 --> 00:03:31,170
you have N100 features, then

104
00:03:31,180 --> 00:03:33,310
you're trying to fit a parameter

105
00:03:33,320 --> 00:03:35,820
vector theta--which is N+1

106
00:03:35,830 --> 00:03:40,130
dimensional,so it's 101 dimensional--we're trying

107
00:03:40,140 --> 00:03:43,020
to fit 101 parameters from just ten training examples.

108
00:03:43,030 --> 00:03:45,130
And this turns out

109
00:03:45,140 --> 00:03:48,440
to sometimes work, but to not always be a good idea.

110
00:03:48,450 --> 00:03:50,570
Because, as we'll see later,

111
00:03:50,580 --> 00:03:52,460
you might not have enough data,

112
00:03:52,470 --> 00:03:54,620
if you have only 10 examples, to

113
00:03:54,630 --> 00:03:58,030
fit 100 or 101 parameters.

114
00:03:58,040 --> 00:03:59,450
We'll see later in this course

115
00:03:59,460 --> 00:04:00,910
why this might be too

116
00:04:00,920 --> 00:04:03,950
many data to fit this many parameters.

117
00:04:03,960 --> 00:04:05,760
But commonly, what we

118
00:04:05,770 --> 00:04:07,110
do then, if M is

119
00:04:07,120 --> 00:04:08,440
less than N, is to see

120
00:04:08,450 --> 00:04:10,130
if we can either delete

121
00:04:10,140 --> 00:04:11,590
some features or to use

122
00:04:11,600 --> 00:04:13,550
a technique called regularization, which is

123
00:04:13,560 --> 00:04:15,150
something that we'll talk

124
00:04:15,160 --> 00:04:16,390
about later in this course as

125
00:04:16,400 --> 00:04:17,940
well, that will kind of

126
00:04:17,950 --> 00:04:19,610
let you fit in all

127
00:04:19,620 --> 00:04:20,870
the parameters, use a lot

128
00:04:20,880 --> 00:04:21,920
of features, even if you

129
00:04:21,930 --> 00:04:23,620
have a relatively small training set.

130
00:04:23,630 --> 00:04:27,330
But, this, this regularization will be a later topic in this course.

131
00:04:27,340 --> 00:04:29,600
But to summarize, if ever

132
00:04:29,610 --> 00:04:31,470
you find that x transfers

133
00:04:31,480 --> 00:04:33,930
x is singular, or alternatively

134
00:04:33,940 --> 00:04:36,590
find there is non-invertible, what I

135
00:04:36,600 --> 00:04:38,290
recommend you do is first

136
00:04:38,300 --> 00:04:40,120
look at your features and see

137
00:04:40,130 --> 00:04:41,830
if you have redundant features, like

138
00:04:41,840 --> 00:04:43,530
this X1 X2, you know,

139
00:04:43,540 --> 00:04:45,030
being linearly dependent, or

140
00:04:45,040 --> 00:04:47,290
being a linear function of each other like so.

141
00:04:47,300 --> 00:04:48,800
And, if you do have redundant

142
00:04:48,810 --> 00:04:51,280
features and if you just, you know, delete one of these features.

143
00:04:51,290 --> 00:04:52,910
You really don't need both of these features.

144
00:04:52,920 --> 00:04:54,260
If you just delete one of

145
00:04:54,270 --> 00:04:56,200
these features, that would solve

146
00:04:56,210 --> 00:04:59,050
your non-invertibility problem and,

147
00:04:59,060 --> 00:05:00,250
so I will first think

148
00:05:00,260 --> 00:05:02,390
through my features and check if any are redundant.

149
00:05:02,400 --> 00:05:03,590
And if so, then you know,

150
00:05:03,600 --> 00:05:06,820
keep deleting redundant features until they are no longer redundant.

151
00:05:06,830 --> 00:05:08,360
And if your features are

152
00:05:08,370 --> 00:05:11,620
not redundant, I would check if I might have too many features.

153
00:05:11,630 --> 00:05:12,830
And if that's the case, I

154
00:05:12,840 --> 00:05:14,940
would either delete some features

155
00:05:14,950 --> 00:05:16,210
if I can bare to use

156
00:05:16,220 --> 00:05:17,850
fewer features or else

157
00:05:17,860 --> 00:05:20,400
I would consider using regularization, which

158
00:05:20,410 --> 00:05:23,750
is this topic that we will talk about later.

159
00:05:24,030 --> 00:05:25,170
So, that's it for the

160
00:05:25,180 --> 00:05:26,840
normal equation and now

161
00:05:26,850 --> 00:05:27,970
what it means for, if the

162
00:05:27,980 --> 00:05:31,480
matrix X transfers X is non-invertible.

163
00:05:31,490 --> 00:05:32,540
But this is a problem that

164
00:05:32,550 --> 00:05:35,490
you should run, that hopefully you run into pretty rarely.

165
00:05:35,500 --> 00:05:36,970
And, if you just implement it in

166
00:05:36,980 --> 00:05:38,700
octave using P in, using

167
00:05:38,710 --> 00:05:40,210
the P in function, which is

168
00:05:40,220 --> 00:05:42,180
called a pseudo-inverse function.

169
00:05:42,190 --> 00:05:43,820
So we use a different linear

170
00:05:43,830 --> 00:05:46,970
algebra ID, called a pseudo-inverse.

171
00:05:46,980 --> 00:05:48,580
But that implementation should just

172
00:05:48,590 --> 00:05:52,640
do the right thing, even if X transfers X is non-invertible.

173
00:05:52,650 --> 00:05:54,490
Which should happen pretty rarely anyway,

174
00:05:54,500 --> 00:05:55,720
so should not be

175
00:05:55,730 --> 00:05:59,490
a problem for most implementations of linear regression.

