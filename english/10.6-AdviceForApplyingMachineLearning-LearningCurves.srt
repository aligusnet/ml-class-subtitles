1
00:00:00,090 --> 00:00:03,300
In this video, I'd like to tell you about learning curves.

2
00:00:03,310 --> 00:00:06,700
Learning curves is often a very useful thing to plot.

3
00:00:06,710 --> 00:00:08,420
If either you wanted to sanity check

4
00:00:08,430 --> 00:00:10,390
that your algorithm is working correctly,

5
00:00:10,400 --> 00:00:13,940
or if you want to improve the performance of the algorithm.

6
00:00:13,950 --> 00:00:15,300
And learning curves is a

7
00:00:15,310 --> 00:00:16,810
tool that I actually use

8
00:00:16,820 --> 00:00:18,280
very often to try to

9
00:00:18,290 --> 00:00:20,170
diagnose if a physical learning algorithm may be

10
00:00:20,180 --> 00:00:24,720
suffering from bias, sort of variance problem or a bit of both.

11
00:00:27,170 --> 00:00:28,820
Here's what a learning curve is.

12
00:00:28,830 --> 00:00:30,690
To plot a learning curve, what

13
00:00:30,700 --> 00:00:32,200
I usually do is plot

14
00:00:32,210 --> 00:00:35,020
j train which is, say,

15
00:00:35,030 --> 00:00:36,430
average squared error on my training

16
00:00:36,440 --> 00:00:39,330
set or Jcv which is

17
00:00:39,340 --> 00:00:41,580
the average squared error on my cross validation set.

18
00:00:41,590 --> 00:00:43,130
And I'm going to plot

19
00:00:43,140 --> 00:00:44,490
that as a function

20
00:00:44,500 --> 00:00:47,220
of m, that is as a function

21
00:00:47,230 --> 00:00:51,940
of the number of training examples I have.

22
00:00:51,950 --> 00:00:53,640
And so m is usually a constant like maybe I just have, you know, a 100

23
00:00:53,650 --> 00:00:55,320
training examples but what I'm

24
00:00:55,330 --> 00:00:57,850
going to do is artificially with

25
00:00:57,860 --> 00:00:59,490
use my training set exercise. So, I

26
00:00:59,500 --> 00:01:01,830
deliberately limit myself to using only,

27
00:01:01,840 --> 00:01:03,650
say, 10 or 20 or

28
00:01:03,660 --> 00:01:06,160
30 or 40 training examples and

29
00:01:06,170 --> 00:01:07,730
plot what the training error is and

30
00:01:07,740 --> 00:01:10,030
what the cross validation is for this

31
00:01:10,040 --> 00:01:12,610
smallest training set exercises.

So

32
00:01:12,620 --> 00:01:14,260
let's see what these plots may look

33
00:01:14,270 --> 00:01:15,720
like. Suppose I have only

34
00:01:15,730 --> 00:01:17,380
one training example like that

35
00:01:17,390 --> 00:01:18,850
shown in this this first example

36
00:01:18,860 --> 00:01:20,240
here and let's say I'm fitting a quadratic function. Well, I

37
00:01:20,250 --> 00:01:22,460


38
00:01:22,470 --> 00:01:25,030
have only one training example. I'm

39
00:01:25,040 --> 00:01:26,640
going to be able to fit it perfectly

40
00:01:26,650 --> 00:01:28,750
right? You know, just fit the quadratic function. I'm

41
00:01:28,760 --> 00:01:30,140
going to have 0

42
00:01:30,150 --> 00:01:32,560
error on the one training example. If I

43
00:01:32,570 --> 00:01:34,230
have two training examples. Well the quadratic function can also fit that very well. So,

44
00:01:34,240 --> 00:01:37,040


45
00:01:37,050 --> 00:01:38,740
even if I am using regularization,

46
00:01:38,750 --> 00:01:41,070
I can probably fit this quite well.

47
00:01:41,080 --> 00:01:42,020
And if I am using no neural regularization,

48
00:01:42,030 --> 00:01:45,430
I'm going to fit this perfectly and

49
00:01:45,440 --> 00:01:47,250
if I have three training examples

50
00:01:47,260 --> 00:01:48,650
again. Yeah, I can fit a quadratic

51
00:01:48,660 --> 00:01:51,540
function perfectly so if

52
00:01:51,550 --> 00:01:52,620
m equals 1 or m equals 2 or m equals 3,

53
00:01:52,630 --> 00:01:54,840


54
00:01:54,850 --> 00:01:57,340
my training error

55
00:01:57,350 --> 00:01:59,100
on my training set is

56
00:01:59,110 --> 00:02:01,210
going to be 0 assuming I'm

57
00:02:01,220 --> 00:02:03,140
not using regularization or it may

58
00:02:03,150 --> 00:02:04,550
slightly large in 0 if

59
00:02:04,560 --> 00:02:06,490
I'm using regularization and

60
00:02:06,500 --> 00:02:07,730
by the way if I have

61
00:02:07,740 --> 00:02:09,930
a large training set and I'm artificially

62
00:02:09,940 --> 00:02:11,110
restricting the size of my

63
00:02:11,120 --> 00:02:13,820
training set in order to J train.

64
00:02:13,830 --> 00:02:15,100
Here if I set

65
00:02:15,110 --> 00:02:17,030
M equals 3, say, and I

66
00:02:17,040 --> 00:02:19,260
train on only three examples,

67
00:02:19,270 --> 00:02:21,100
then, for this figure I

68
00:02:21,110 --> 00:02:22,820
am going to measure my training error

69
00:02:22,830 --> 00:02:24,540
only on the three examples that

70
00:02:24,550 --> 00:02:27,080
actually fit my data too

71
00:02:27,150 --> 00:02:28,280
and so even I have to say

72
00:02:28,290 --> 00:02:31,420
a 100 training examples but if I want to plot what my

73
00:02:31,430 --> 00:02:32,830
training error is the m equals 3. What I'm going to do

74
00:02:32,840 --> 00:02:34,260


75
00:02:34,270 --> 00:02:35,330
is to measure the

76
00:02:35,340 --> 00:02:36,740
training error on the

77
00:02:36,750 --> 00:02:41,280
three examples that I've actually fit to my hypothesis 2.

78
00:02:41,290 --> 00:02:43,000
And not all the other examples that I have

79
00:02:43,010 --> 00:02:45,130
deliberately omitted from the training

80
00:02:45,140 --> 00:02:46,950
process. So just to summarize what we've

81
00:02:46,960 --> 00:02:48,810
seen is that if the training set

82
00:02:48,820 --> 00:02:50,620
size is small then the

83
00:02:50,630 --> 00:02:52,950
training error is going to be small as well.

84
00:02:52,960 --> 00:02:53,920
Because you know, we have a

85
00:02:53,930 --> 00:02:55,340
small training set is

86
00:02:55,350 --> 00:02:56,890
going to be very easy to

87
00:02:56,900 --> 00:02:58,710
fit your training set

88
00:02:58,720 --> 00:02:59,780
very well may be even

89
00:02:59,790 --> 00:03:03,180
perfectly now say

90
00:03:03,190 --> 00:03:04,670
we have m equals 4 for example. Well then

91
00:03:04,680 --> 00:03:06,910
a quadratic function can be

92
00:03:06,920 --> 00:03:08,090
a longer fit this data set

93
00:03:08,100 --> 00:03:09,780
perfectly and if I

94
00:03:09,790 --> 00:03:11,450
have m equals 5 then you

95
00:03:11,460 --> 00:03:14,080
know, maybe quadratic function will fit to stay there so

96
00:03:14,090 --> 00:03:16,970
so, then as my training set gets larger.

97
00:03:16,980 --> 00:03:18,610
It becomes harder and harder to

98
00:03:18,620 --> 00:03:20,050
ensure that I can

99
00:03:20,060 --> 00:03:21,950
find the quadratic function that process through

100
00:03:21,960 --> 00:03:25,830
all my examples perfectly. So

101
00:03:25,840 --> 00:03:27,680
in fact as the training set size

102
00:03:27,690 --> 00:03:29,290
grows what you find

103
00:03:29,300 --> 00:03:31,300
is that my average training error

104
00:03:31,310 --> 00:03:33,490
actually increases and so if you plot

105
00:03:33,500 --> 00:03:35,210
this figure what you find

106
00:03:35,220 --> 00:03:37,120
is that the training set

107
00:03:37,130 --> 00:03:38,930
error that is the average

108
00:03:38,940 --> 00:03:41,290
error on your hypothesis grows

109
00:03:41,300 --> 00:03:45,010
as m grows and just to repeat when the intuition is that when

110
00:03:45,020 --> 00:03:46,490
m is small when you have very

111
00:03:46,500 --> 00:03:48,340
few training examples. It's pretty

112
00:03:48,350 --> 00:03:49,780
easy to fit every single

113
00:03:49,790 --> 00:03:51,600
one of your training examples perfectly and

114
00:03:51,610 --> 00:03:52,930
so your error is going

115
00:03:52,940 --> 00:03:54,700
to be small whereas

116
00:03:54,710 --> 00:03:56,450
when m is larger then gets

117
00:03:56,460 --> 00:03:58,210
harder all the training

118
00:03:58,220 --> 00:04:00,420
examples perfectly and so

119
00:04:00,430 --> 00:04:02,360
your training set error becomes

120
00:04:02,370 --> 00:04:06,710
more larger now, how about the cross validation error.

121
00:04:06,720 --> 00:04:08,580
Well, the cross validation is

122
00:04:08,590 --> 00:04:10,340
my error on this cross

123
00:04:10,350 --> 00:04:12,870
validation set that I haven't seen and

124
00:04:12,880 --> 00:04:14,710
so, you know, when I have

125
00:04:14,720 --> 00:04:16,070
a very small training set, I'm

126
00:04:16,080 --> 00:04:17,010
not going to generalize well, just

127
00:04:17,020 --> 00:04:19,840
not going to do well on that.

128
00:04:19,850 --> 00:04:21,610
So, right, this hypothesis here doesn't

129
00:04:21,620 --> 00:04:23,010
look like a good one, and

130
00:04:23,020 --> 00:04:24,040
it's only when I get

131
00:04:24,050 --> 00:04:25,490
a larger training set that,

132
00:04:25,500 --> 00:04:26,880
you know, I'm starting to get

133
00:04:26,890 --> 00:04:28,470
hypotheses that maybe fit

134
00:04:28,480 --> 00:04:31,370
the data somewhat better.

135
00:04:31,380 --> 00:04:32,250
So your cross validation error and

136
00:04:32,260 --> 00:04:35,880
your test set error will tend

137
00:04:35,890 --> 00:04:37,460
to decrease as your training

138
00:04:37,470 --> 00:04:39,240
set size increases because the

139
00:04:39,250 --> 00:04:40,980
more data you have, the better

140
00:04:40,990 --> 00:04:44,000
you do at generalizing to new examples.

141
00:04:44,010 --> 00:04:47,550
So, just the more data you have, the better the hypothesis you fit.

142
00:04:47,560 --> 00:04:49,410
So if you plot j train,

143
00:04:49,420 --> 00:04:52,480
and Jcv this is the sort of thing that you get.

144
00:04:52,490 --> 00:04:53,760
Now let's look at what

145
00:04:53,770 --> 00:04:55,350
the learning curves may look like

146
00:04:55,360 --> 00:04:56,920
if we have either high

147
00:04:56,930 --> 00:04:58,910
bias or high variance problems.

148
00:04:58,920 --> 00:05:00,820
Suppose your hypothesis has high

149
00:05:00,830 --> 00:05:02,360
bias and to explain this

150
00:05:02,370 --> 00:05:03,930
I'm going to use a, set an

151
00:05:03,940 --> 00:05:05,430
example, of fitting a straight

152
00:05:05,440 --> 00:05:06,760
line to data that, you

153
00:05:06,770 --> 00:05:09,530
know, can't really be fit well by a straight line.

154
00:05:09,540 --> 00:05:13,830
So we end up with a hypotheses that maybe looks like that.

155
00:05:13,910 --> 00:05:15,740
Now let's think what would

156
00:05:15,750 --> 00:05:17,460
happen if we were to increase

157
00:05:17,470 --> 00:05:19,150
the training set size. So if

158
00:05:19,160 --> 00:05:20,580
instead of five examples like

159
00:05:20,590 --> 00:05:22,560
what I've drawn there, imagine that

160
00:05:22,570 --> 00:05:25,270
we have a lot more training examples.

161
00:05:25,280 --> 00:05:27,970
Well what happens, if you fit a straight line to this.

162
00:05:27,980 --> 00:05:30,030
What you find is that, you

163
00:05:30,040 --> 00:05:31,680
end up with you know, pretty much the same straight line.

164
00:05:31,690 --> 00:05:33,520
I mean a straight line that

165
00:05:33,530 --> 00:05:35,260
just cannot fit this

166
00:05:35,270 --> 00:05:37,880
data and getting a ton more data, well

167
00:05:37,890 --> 00:05:40,220
the straight line isn't going to change that much.

168
00:05:40,230 --> 00:05:41,830
This is the best possible straight-line

169
00:05:41,840 --> 00:05:42,880
fit to this data, but the

170
00:05:42,890 --> 00:05:44,310
straight line just can't fit this

171
00:05:44,320 --> 00:05:45,860
data set that well. So,

172
00:05:45,870 --> 00:05:48,920
if you plot across validation error,

173
00:05:49,260 --> 00:05:51,310
this is what it will look like.

174
00:05:51,320 --> 00:05:55,400
Option on the left, if you have already a miniscule training set size like you know,

175
00:05:55,410 --> 00:05:58,540
maybe just one training example and is not going to do well.

176
00:05:58,550 --> 00:05:59,650
But by the time you have

177
00:05:59,660 --> 00:06:00,930
reached a certain number of training

178
00:06:00,940 --> 00:06:02,800
examples, you have almost

179
00:06:02,810 --> 00:06:04,190
fit the best possible straight

180
00:06:04,200 --> 00:06:05,480
line, and even if

181
00:06:05,490 --> 00:06:06,470
you end up with a much

182
00:06:06,480 --> 00:06:07,960
larger training set size, a

183
00:06:07,970 --> 00:06:10,000
much larger value of m,

184
00:06:10,010 --> 00:06:12,360
you know, you're basically getting the same straight line,

185
00:06:12,370 --> 00:06:14,470
and so, the cross-validation error

186
00:06:14,480 --> 00:06:15,640
- let me label that -

187
00:06:15,650 --> 00:06:17,130
or test set error or

188
00:06:17,140 --> 00:06:18,980
plateau out, or flatten out

189
00:06:18,990 --> 00:06:20,900
pretty soon, once you reached

190
00:06:20,910 --> 00:06:23,260
beyond a certain the number

191
00:06:23,270 --> 00:06:25,120
of training examples, unless you

192
00:06:25,130 --> 00:06:28,380
pretty much fit the best possible straight line.

193
00:06:28,390 --> 00:06:30,110
And how about training error?

194
00:06:30,120 --> 00:06:34,550
Well, the training error will again be small.

195
00:06:34,620 --> 00:06:36,750
And what you find

196
00:06:36,760 --> 00:06:38,200
in the high bias case is

197
00:06:38,210 --> 00:06:40,990
that the training error will end

198
00:06:41,000 --> 00:06:42,820
up close to the cross

199
00:06:42,830 --> 00:06:44,800
validation error, because you

200
00:06:44,810 --> 00:06:46,580
have so few parameters and so

201
00:06:46,590 --> 00:06:48,890
much data, at least when m is large.

202
00:06:48,900 --> 00:06:50,210
The performance on the training

203
00:06:50,220 --> 00:06:53,790
set and the cross validation set will be very similar.

204
00:06:53,800 --> 00:06:54,860
And so, this is what your

205
00:06:54,870 --> 00:06:56,760
learning curves will look like,

206
00:06:56,770 --> 00:07:00,210
if you have an algorithm that has high bias.

207
00:07:00,220 --> 00:07:01,620
And finally, the problem with

208
00:07:01,630 --> 00:07:03,440
high bias is reflected in

209
00:07:03,450 --> 00:07:05,570
the fact that both the

210
00:07:05,580 --> 00:07:07,410
cross validation error and the

211
00:07:07,420 --> 00:07:09,550
training error are high,

212
00:07:09,560 --> 00:07:10,640
and so you end up with

213
00:07:10,650 --> 00:07:12,270
a relatively high value of

214
00:07:12,280 --> 00:07:15,360
both Jcv and the j train.

215
00:07:15,370 --> 00:07:17,110
This also implies something very

216
00:07:17,120 --> 00:07:18,790
interesting, which is that,

217
00:07:18,800 --> 00:07:20,350
if a learning algorithm has high

218
00:07:20,360 --> 00:07:22,380
bias, as we

219
00:07:22,390 --> 00:07:24,050
get more and more training examples,

220
00:07:24,060 --> 00:07:25,200
that is, as we move to

221
00:07:25,210 --> 00:07:26,730
the right of this figure, we'll

222
00:07:26,740 --> 00:07:28,210
notice that the cross

223
00:07:28,220 --> 00:07:29,730
validation error isn't going

224
00:07:29,740 --> 00:07:31,550
down much, it's basically fattened

225
00:07:31,560 --> 00:07:32,940
up, and so if

226
00:07:32,950 --> 00:07:36,520
learning algorithms are really suffering from high bias.

227
00:07:36,640 --> 00:07:38,360
Getting more training data by

228
00:07:38,370 --> 00:07:40,180
itself will actually not help

229
00:07:40,190 --> 00:07:41,750
that much,and as our figure

230
00:07:41,760 --> 00:07:43,200
example in the figure

231
00:07:43,210 --> 00:07:46,050
on the right, here we had only five training.

232
00:07:46,060 --> 00:07:48,540
examples, and we fill certain straight line.

233
00:07:48,550 --> 00:07:49,530
And when we had a ton

234
00:07:49,540 --> 00:07:51,030
more training data, we still

235
00:07:51,040 --> 00:07:53,190
end up with roughly the same straight line.

236
00:07:53,200 --> 00:07:54,430
And so if the learning algorithm

237
00:07:54,440 --> 00:07:57,640
has high bias give me a lot more training data.

238
00:07:57,650 --> 00:07:59,820
That doesn't actually help you

239
00:07:59,830 --> 00:08:01,880
get a much lower cross validation

240
00:08:01,890 --> 00:08:03,720
error or test set error.

241
00:08:03,730 --> 00:08:05,240
So knowing if your learning

242
00:08:05,250 --> 00:08:06,770
algorithm is suffering from high

243
00:08:06,780 --> 00:08:08,090
bias seems like a useful

244
00:08:08,100 --> 00:08:09,630
thing to know because this can

245
00:08:09,640 --> 00:08:11,280
prevent you from wasting a

246
00:08:11,290 --> 00:08:12,910
lot of time collecting more training

247
00:08:12,920 --> 00:08:16,190
data where it might just not end up being helpful.

248
00:08:16,200 --> 00:08:17,130
Next let us look at the

249
00:08:17,140 --> 00:08:19,460
setting of a learning algorithm

250
00:08:19,470 --> 00:08:21,580
that may have high variance.

251
00:08:21,590 --> 00:08:23,540
Let us just look at the

252
00:08:23,550 --> 00:08:25,110
training error in a around if

253
00:08:25,120 --> 00:08:26,670
you have very smart training

254
00:08:26,680 --> 00:08:29,120
set like five training examples shown on

255
00:08:29,130 --> 00:08:31,140
the figure on the right and

256
00:08:31,150 --> 00:08:32,190
if we're fitting say a

257
00:08:32,200 --> 00:08:34,370
very high order polynomial,

258
00:08:34,380 --> 00:08:37,080
and I've written a hundredth degree polynomial which

259
00:08:37,090 --> 00:08:39,910
really no one uses, but just an illustration.

260
00:08:39,920 --> 00:08:41,540
And if we're using a

261
00:08:41,550 --> 00:08:43,790
fairly small value of lambda,

262
00:08:43,800 --> 00:08:45,060
maybe not zero, but a fairly

263
00:08:45,070 --> 00:08:47,030
small value of lambda, then

264
00:08:47,040 --> 00:08:48,180
we'll end up, you know,

265
00:08:48,190 --> 00:08:50,850
fitting this data very well that with

266
00:08:50,860 --> 00:08:54,370
a function that overfits this.

267
00:08:54,380 --> 00:08:55,980
So, if the training

268
00:08:55,990 --> 00:08:58,310
set size is small, our training

269
00:08:58,320 --> 00:09:00,020
error, that is, j train

270
00:09:00,030 --> 00:09:03,120
of theta will be small.

271
00:09:03,130 --> 00:09:04,930
And as this training set size increases

272
00:09:04,940 --> 00:09:05,990
a bit, you know, we may

273
00:09:06,000 --> 00:09:07,320
still be overfitting this

274
00:09:07,330 --> 00:09:09,770
data a little bit but

275
00:09:09,780 --> 00:09:12,010
it also becomes slightly harder to

276
00:09:12,020 --> 00:09:13,930
fit this data set perfectly,

277
00:09:13,940 --> 00:09:15,340
and so, as the training set size

278
00:09:15,350 --> 00:09:16,950
increases, we'll find that

279
00:09:16,960 --> 00:09:19,830
j train increases, because

280
00:09:19,840 --> 00:09:21,250
it is just a little harder to fit

281
00:09:21,260 --> 00:09:22,880
the training set perfectly when we have

282
00:09:22,890 --> 00:09:26,520
more examples, but the training set error will still be pretty low.

283
00:09:26,530 --> 00:09:29,210
Now, how about the cross validation error?

284
00:09:29,220 --> 00:09:31,030
Well, in high variance

285
00:09:31,040 --> 00:09:32,970
setting, a hypothesis is

286
00:09:32,980 --> 00:09:34,280
overfitting and so the

287
00:09:34,290 --> 00:09:36,110
cross validation error will remain

288
00:09:36,120 --> 00:09:37,740
high, even as we

289
00:09:37,750 --> 00:09:39,250
get you know, a moderate number

290
00:09:39,260 --> 00:09:41,160
of training examples and, so

291
00:09:41,170 --> 00:09:43,720
maybe, the cross validation

292
00:09:43,730 --> 00:09:45,650
error may look like that.

293
00:09:45,660 --> 00:09:47,820
And the indicative diagnostic that we

294
00:09:47,830 --> 00:09:50,200
have a high variance problem,

295
00:09:50,210 --> 00:09:51,710
is the fact that there's

296
00:09:51,720 --> 00:09:54,330
this large gap between

297
00:09:54,340 --> 00:09:57,430
the training error and the cross validation error.

298
00:09:57,440 --> 00:09:58,710
And looking at this figure.

299
00:09:58,720 --> 00:10:00,430
If we think about adding more

300
00:10:00,440 --> 00:10:02,100
training data, that is, taking

301
00:10:02,110 --> 00:10:03,780
this figure and extrapolating to

302
00:10:03,790 --> 00:10:05,320
the right, we can kind

303
00:10:05,330 --> 00:10:07,020
of tell that, you know the

304
00:10:07,030 --> 00:10:08,470
two curves, the blue curve

305
00:10:08,480 --> 00:10:11,410
and the magenta curve, are converging to each other.

306
00:10:11,420 --> 00:10:12,510
And so, if we were to

307
00:10:12,520 --> 00:10:13,970
extrapolate this figure to

308
00:10:13,980 --> 00:10:21,350
the right, then it

309
00:10:21,360 --> 00:10:23,160
seems it likely that the

310
00:10:23,170 --> 00:10:24,260
training error will keep on

311
00:10:24,270 --> 00:10:27,120
going up and the

312
00:10:27,130 --> 00:10:29,990
cross-validation error would keep on going down.

313
00:10:30,000 --> 00:10:33,000
And the thing we really care about is the cross-validation error

314
00:10:33,010 --> 00:10:35,290
or the test set error, right?

315
00:10:35,300 --> 00:10:36,720
So in this sort

316
00:10:36,730 --> 00:10:38,220
of figure, we can tell that

317
00:10:38,230 --> 00:10:39,810
if we keep on adding training

318
00:10:39,820 --> 00:10:41,040
examples and extrapolate to the

319
00:10:41,050 --> 00:10:43,280
right, well our cross validation

320
00:10:43,290 --> 00:10:45,110
error will keep on coming down.

321
00:10:45,120 --> 00:10:46,320
And, so, in the high

322
00:10:46,330 --> 00:10:48,170
variance setting, getting more

323
00:10:48,180 --> 00:10:50,160
training data is, indeed,

324
00:10:50,170 --> 00:10:51,510
likely to help.

325
00:10:51,520 --> 00:10:53,050
And so again, this seems like a

326
00:10:53,060 --> 00:10:54,320
useful thing to know if your

327
00:10:54,330 --> 00:10:56,140
learning algorithm is suffering

328
00:10:56,150 --> 00:10:57,800
from a high variance problem, because

329
00:10:57,810 --> 00:10:59,210
that tells you, for example that it

330
00:10:59,220 --> 00:11:00,670
may be be worth your while

331
00:11:00,680 --> 00:11:03,690
to see if you can go and get some more training data.

332
00:11:03,700 --> 00:11:05,320
Now, on the previous slide

333
00:11:05,330 --> 00:11:06,960
and this slide, I've drawn fairly

334
00:11:06,970 --> 00:11:08,890
clean fairly idealized curves.

335
00:11:08,900 --> 00:11:10,160
If you plot these curves for

336
00:11:10,170 --> 00:11:12,490
an actual learning algorithm, sometimes

337
00:11:12,500 --> 00:11:14,550
you will actually see, you know, pretty

338
00:11:14,560 --> 00:11:16,590
much curves, like what I've drawn here.

339
00:11:16,600 --> 00:11:18,140
Although, sometimes you see curves

340
00:11:18,150 --> 00:11:19,220
that are a little bit noisier and

341
00:11:19,230 --> 00:11:21,080
a little bit messier than this.

342
00:11:21,090 --> 00:11:22,610
But plotting learning curves like

343
00:11:22,620 --> 00:11:24,110
these can often tell

344
00:11:24,120 --> 00:11:25,560
you, can often help you

345
00:11:25,570 --> 00:11:26,940
figure out if your learning algorithm is

346
00:11:26,950 --> 00:11:29,160
suffering from bias, or variance or even a little bit of both.

347
00:11:29,170 --> 00:11:31,190
So when I'm

348
00:11:31,200 --> 00:11:32,750
trying to improve the performance of

349
00:11:32,760 --> 00:11:34,250
a learning algorithm, one thing

350
00:11:34,260 --> 00:11:35,950
that I'll almost always do

351
00:11:35,960 --> 00:11:37,960
is plot these learning

352
00:11:37,970 --> 00:11:39,480
curves, and usually this will

353
00:11:39,490 --> 00:11:43,210
give you a better sense of whether there is a bias or variance problem.

354
00:11:44,280 --> 00:11:45,410
And in the next video

355
00:11:45,420 --> 00:11:46,640
we'll see how this can

356
00:11:46,650 --> 00:11:48,440
help suggest specific actions is

357
00:11:48,450 --> 00:11:50,250
to take, or to not take,

358
00:11:50,260 --> 00:11:54,750
in order to try to improve the performance of your learning algorithm.

