1
00:00:00,130 --> 00:00:01,230
In this and the next

2
00:00:01,240 --> 00:00:02,130
video I want to work

3
00:00:02,140 --> 00:00:04,520
through a detailed example, showing

4
00:00:04,530 --> 00:00:06,210
how a neural network can compute

5
00:00:06,220 --> 00:00:07,960
a complex nonlinear function of

6
00:00:07,970 --> 00:00:09,940
the input and hopefully, this will

7
00:00:09,950 --> 00:00:11,500
give you a good sense of why

8
00:00:11,510 --> 00:00:13,040
Neural Networks can be used

9
00:00:13,050 --> 00:00:16,310
to learn complex, nonlinear hypotheses.

10
00:00:16,790 --> 00:00:18,890
Consider the following problem where

11
00:00:18,900 --> 00:00:20,760
we have input features x1

12
00:00:20,770 --> 00:00:22,300
and x2 that are binary

13
00:00:22,310 --> 00:00:23,980
values, so either zero or one.

14
00:00:23,990 --> 00:00:25,500
So x1 and x2 can each

15
00:00:25,510 --> 00:00:28,650
take on only one of two possible values.

16
00:00:28,660 --> 00:00:29,980
In this example, I've drawn

17
00:00:29,990 --> 00:00:31,520
only two positive examples and

18
00:00:31,530 --> 00:00:33,310
two negative examples, but you

19
00:00:33,320 --> 00:00:34,530
can think of this as a

20
00:00:34,540 --> 00:00:36,280
simplified version of a

21
00:00:36,290 --> 00:00:37,910
more complex learning problem where

22
00:00:37,920 --> 00:00:39,020
we may have a bunch

23
00:00:39,030 --> 00:00:40,470
of positive examples in the upper

24
00:00:40,480 --> 00:00:41,460
right and the lower left and

25
00:00:41,470 --> 00:00:43,570
a bunch of negative examples to notify

26
00:00:43,580 --> 00:00:46,130
the circles, and what

27
00:00:46,140 --> 00:00:48,320
we'd like to do is learn a nonlinear, you know,

28
00:00:48,330 --> 00:00:50,200
decision boundary that we

29
00:00:50,210 --> 00:00:53,710
need to separate the positive and the negative examples.

30
00:00:53,750 --> 00:00:55,060
So how can a neural

31
00:00:55,070 --> 00:00:56,700
network do this and rather than

32
00:00:56,710 --> 00:00:57,590
use an example on the

33
00:00:57,600 --> 00:00:59,670
right. I'm going to use this, maybe easier

34
00:00:59,680 --> 00:01:02,610
to examine example on the left.

35
00:01:02,620 --> 00:01:04,100
Concretely, what this is

36
00:01:04,110 --> 00:01:05,980
is really computing the target

37
00:01:05,990 --> 00:01:10,060
label y equals x1 XOR x2.

38
00:01:10,070 --> 00:01:11,900
Or this is actually the

39
00:01:11,910 --> 00:01:14,690
x1 XNOR x2 function

40
00:01:14,700 --> 00:01:16,390
where XNOR is the alternative

41
00:01:16,400 --> 00:01:19,340
notation for "not x1 or x2".

42
00:01:19,350 --> 00:01:20,750
So x1, XOR or

43
00:01:20,760 --> 00:01:23,200
x2 - that's true only

44
00:01:23,210 --> 00:01:25,180
if exactly one of

45
00:01:25,190 --> 00:01:27,950
x1 or x2 is equal to 1.

46
00:01:27,960 --> 00:01:29,440
It turns out that the specific

47
00:01:29,450 --> 00:01:30,800
example I'm going to use works out

48
00:01:30,810 --> 00:01:33,010
a little bit better if we

49
00:01:33,020 --> 00:01:35,450
use the XNOR example, instead.

50
00:01:35,460 --> 00:01:36,710
These two are the same, of course.

51
00:01:36,720 --> 00:01:38,770
It means not x1 XOR

52
00:01:38,780 --> 00:01:40,310
x2, and so we're going

53
00:01:40,320 --> 00:01:42,940
to have positive examples

54
00:01:42,950 --> 00:01:44,520
if either both are true or

55
00:01:44,530 --> 00:01:46,610
both are false and we'll

56
00:01:46,620 --> 00:01:49,980
have that's y equals 1, y equals 1 and

57
00:01:49,990 --> 00:01:51,850
we're going to have y equals 0 if

58
00:01:51,860 --> 00:01:52,750
only one of them is

59
00:01:52,760 --> 00:01:53,990
true and we want

60
00:01:54,000 --> 00:01:54,850
to figure out if we can

61
00:01:54,860 --> 00:01:58,710
get a neural network to fit to this sort of training set.

62
00:01:59,160 --> 00:02:00,440
In order to build up

63
00:02:00,450 --> 00:02:02,070
to a network that fits the

64
00:02:02,080 --> 00:02:05,340
XNOR example, we're going

65
00:02:05,350 --> 00:02:07,040
to start to a slightly simpler one

66
00:02:07,050 --> 00:02:10,750
and show a network that fits the AND function.

67
00:02:10,760 --> 00:02:12,300
Concretely, lets say we

68
00:02:12,310 --> 00:02:14,230
have inputs x1 and

69
00:02:14,240 --> 00:02:17,810
x2 that are again binary. So, it's either zero or one.

70
00:02:17,820 --> 00:02:18,750
And let's say our target

71
00:02:18,760 --> 00:02:21,900
labels y are you know, is

72
00:02:21,910 --> 00:02:23,850
equal to x1 and x2.

73
00:02:23,860 --> 00:02:26,370
This is a logical AND.

74
00:02:30,740 --> 00:02:32,050
So can we get a

75
00:02:32,060 --> 00:02:35,050
one unit network to compute

76
00:02:35,060 --> 00:02:37,390
this logical AND function?

77
00:02:37,400 --> 00:02:38,680
In order to do so, I'm

78
00:02:38,690 --> 00:02:40,570
going to actually draw in

79
00:02:40,580 --> 00:02:44,280
the bias unit as well, the plus one unit.

80
00:02:45,030 --> 00:02:46,760
Now, let me just assign some

81
00:02:46,770 --> 00:02:48,150
values to the weights or

82
00:02:48,160 --> 00:02:50,440
the parameters of this network.

83
00:02:50,450 --> 00:02:52,810
I am going to write down the parameters on this diagram.

84
00:02:52,820 --> 00:02:55,590
Write minus 30 here

85
00:02:56,360 --> 00:02:58,700
plus 20 and plus

86
00:02:58,710 --> 00:02:59,960
20 and what this means

87
00:02:59,970 --> 00:03:01,850
is that I'm assigning a value

88
00:03:01,860 --> 00:03:04,110
of minus thirty to the

89
00:03:04,120 --> 00:03:06,110
value associated with x0.

90
00:03:06,120 --> 00:03:07,520
This is plus 1 going

91
00:03:07,530 --> 00:03:09,410
to this unit and a

92
00:03:09,420 --> 00:03:11,240
parameter value of plus 20

93
00:03:11,250 --> 00:03:13,060
that multiplies in x1 in

94
00:03:13,070 --> 00:03:14,670
a value of plus 20 for

95
00:03:14,680 --> 00:03:17,180
the parameter that multiplies into x2.

96
00:03:17,190 --> 00:03:19,050
So, concretely, this is saying

97
00:03:19,060 --> 00:03:20,410
that my hypotheses h of

98
00:03:20,420 --> 00:03:22,400
x is equal to

99
00:03:22,410 --> 00:03:25,480
g of  -30 + 20x1 + 20x2.

100
00:03:25,490 --> 00:03:31,630
So sometimes it's just

101
00:03:31,640 --> 00:03:33,800
convenient to draw these

102
00:03:33,810 --> 00:03:35,610
weights and draw these parameters

103
00:03:35,620 --> 00:03:38,780
up here, you know, in the diagram of the neural network.

104
00:03:38,790 --> 00:03:40,380
And of course this minus 30

105
00:03:40,390 --> 00:03:43,660
this is actually theta 1

106
00:03:43,670 --> 00:03:45,280
of 1,0.

107
00:03:45,290 --> 00:03:47,590
This is theta 1

108
00:03:47,600 --> 00:03:51,550
of 1,1 and that's theta

109
00:03:51,560 --> 00:03:53,280
1 of 1,2

110
00:03:53,290 --> 00:03:54,580
but it's just easier think about

111
00:03:54,590 --> 00:03:56,830
it as, you know, associating these

112
00:03:56,840 --> 00:03:59,930
parameters with the edges of the network.

113
00:04:01,170 --> 00:04:05,040
Let's look at what this little single neuron network will compute.

114
00:04:05,050 --> 00:04:06,710
Just to remind you, the sigmoid

115
00:04:06,720 --> 00:04:09,100
activation function g of z looks like this.

116
00:04:09,110 --> 00:04:11,150
It starts from 0, rises

117
00:04:11,160 --> 00:04:12,740
smoothly, crosses 0.5, and

118
00:04:12,750 --> 00:04:15,720
then it asymptotes at one.

119
00:04:15,730 --> 00:04:17,340
And to give you some landmarks,

120
00:04:17,350 --> 00:04:19,450
if the horizontal axis value

121
00:04:19,460 --> 00:04:23,270
z is equal to 4.6, then

122
00:04:23,840 --> 00:04:26,210
the sigmoid function is equal to 0.99.

123
00:04:26,220 --> 00:04:28,140
This is very close

124
00:04:28,150 --> 00:04:30,340
to 1 and kind of symmetrically

125
00:04:30,350 --> 00:04:33,080
if it is negative 4.6, then

126
00:04:33,090 --> 00:04:35,070
the sigmoid function there is

127
00:04:35,080 --> 00:04:39,320
equal to 0.01 which is very close to 0.

128
00:04:39,440 --> 00:04:41,030
Let's look at the four possible input

129
00:04:41,040 --> 00:04:41,720
values for x1 and x2

130
00:04:41,730 --> 00:04:43,610
and look at whether the hypothesis will

131
00:04:43,620 --> 00:04:47,210
open in that case.

132
00:04:47,220 --> 00:04:48,140
If x1 and x2 are both

133
00:04:48,150 --> 00:04:49,450
equal to 0 - if

134
00:04:49,460 --> 00:04:50,700
you look at this, if

135
00:04:50,710 --> 00:04:52,000
x1 and x2 are both equal

136
00:04:52,010 --> 00:04:55,110
to 0 then the hypotheses of point g of -30.

137
00:04:55,120 --> 00:04:57,280
So, it's like very

138
00:04:57,290 --> 00:04:58,740
far to the left of this diagram.

139
00:04:58,750 --> 00:05:01,580
This will be very close to 0.

140
00:05:01,590 --> 00:05:03,320
If x1 equals 0 and

141
00:05:03,330 --> 00:05:05,540
x2 equals 1 then this

142
00:05:05,550 --> 00:05:07,820
formula here evaluates to

143
00:05:07,830 --> 00:05:09,880
g, thus the sigmoid function applied

144
00:05:09,890 --> 00:05:12,440
to -10 and again,

145
00:05:12,450 --> 00:05:13,870
that's, you know, to the far left

146
00:05:13,880 --> 00:05:15,140
of this plot and so,

147
00:05:15,150 --> 00:05:16,650
that's again very close to 0.

148
00:05:16,660 --> 00:05:19,260
This is also g of -10.

149
00:05:19,270 --> 00:05:21,990
That is if x1

150
00:05:22,000 --> 00:05:24,550
is equal to 1 and

151
00:05:24,560 --> 00:05:26,220
x(2)0, this is -30 plus 20, which is -10.

152
00:05:26,230 --> 00:05:28,580
And finally if

153
00:05:28,590 --> 00:05:30,660
x1 equals 1, x2 equals

154
00:05:30,670 --> 00:05:32,760
1, then you have g of

155
00:05:32,770 --> 00:05:34,180
-30 +20 +20,

156
00:05:34,190 --> 00:05:35,430
so that's g of

157
00:05:35,440 --> 00:05:36,700
+10, which is

158
00:05:36,710 --> 00:05:39,030
therefore very close to 1.

159
00:05:39,040 --> 00:05:40,480
And if you look

160
00:05:40,490 --> 00:05:43,000
in this column, this is

161
00:05:43,010 --> 00:05:45,810
exactly the logical "and" function.

162
00:05:45,820 --> 00:05:47,880
So, this is computing h of

163
00:05:47,890 --> 00:05:50,250
x is, you know,

164
00:05:50,260 --> 00:05:55,190
approximately x1 and x2.

165
00:05:55,200 --> 00:05:56,640
In other words, it outputs

166
00:05:56,650 --> 00:05:58,260
1 if and only

167
00:05:58,270 --> 00:06:00,940
if x1 and x2 are

168
00:06:00,950 --> 00:06:03,350
both equal to 1.

169
00:06:03,360 --> 00:06:05,310
So by writing out our little

170
00:06:05,320 --> 00:06:07,770
truth table like this,

171
00:06:07,780 --> 00:06:09,340
we manage to figure out what's

172
00:06:09,350 --> 00:06:11,640
the logical function that our

173
00:06:11,650 --> 00:06:14,370
neural network computes.

174
00:06:16,990 --> 00:06:18,870
This network shown here computes

175
00:06:18,880 --> 00:06:20,360
the OR function just to

176
00:06:20,370 --> 00:06:22,520
show you how I worked that out.

177
00:06:22,530 --> 00:06:23,670
If you are to write out

178
00:06:23,680 --> 00:06:25,350
the hypotheses you find that

179
00:06:25,360 --> 00:06:27,100
it's computing g of

180
00:06:27,110 --> 00:06:30,160
-10 +20 x1

181
00:06:30,170 --> 00:06:32,260
+20 x2. And so

182
00:06:32,270 --> 00:06:33,510
if you fill in these values you

183
00:06:33,520 --> 00:06:35,450
find that's g of

184
00:06:35,460 --> 00:06:37,810
-10 which is approximately 0,

185
00:06:37,820 --> 00:06:39,030
g of 10 which is

186
00:06:39,040 --> 00:06:40,920
approximately 1, and so on.

187
00:06:40,930 --> 00:06:43,540
These are approximately 1, and approximately

188
00:06:43,550 --> 00:06:46,150
1, and these numbers is

189
00:06:46,160 --> 00:06:47,850
essentially the logical OR

190
00:06:47,860 --> 00:06:50,580
function.

 So, hopefully

191
00:06:50,590 --> 00:06:52,340
with this, you now understand how

192
00:06:52,350 --> 00:06:54,010
single neurons in a

193
00:06:54,020 --> 00:06:55,170
neural network can be used

194
00:06:55,180 --> 00:06:58,990
to compute logical functions like AND and OR and so on.

195
00:06:59,000 --> 00:07:00,780
In the next video, we'll continue

196
00:07:00,790 --> 00:07:04,720
building on these examples and work through a more complex example.

197
00:07:04,730 --> 00:07:06,160
We'll get to show you how

198
00:07:06,170 --> 00:07:07,810
a neural network, now with

199
00:07:07,820 --> 00:07:09,950
multiple layers of units can

200
00:07:09,960 --> 00:07:11,390
be used to compute more complex

201
00:07:11,400 --> 00:07:15,370
functions like the XOR function or the XNOR function.

