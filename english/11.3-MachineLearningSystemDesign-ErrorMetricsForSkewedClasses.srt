1
00:00:00,290 --> 00:00:02,050
In the previous video, I talked

2
00:00:02,060 --> 00:00:04,340
about error analysis and the

3
00:00:04,350 --> 00:00:06,320
importance of having error

4
00:00:06,330 --> 00:00:08,200
metrics, that is of having

5
00:00:08,210 --> 00:00:11,010
a single real number evaluation metric

6
00:00:11,020 --> 00:00:14,300
for your learning algorithm to tell how well it's doing.

7
00:00:14,310 --> 00:00:16,690
In the context of evaluation

8
00:00:16,700 --> 00:00:18,420
and of error metrics, there is

9
00:00:18,430 --> 00:00:20,470
one important case, where it's

10
00:00:20,480 --> 00:00:22,500
particularly tricky to come

11
00:00:22,510 --> 00:00:24,920
up with an appropriate error metric,

12
00:00:24,930 --> 00:00:28,030
or evaluation metric, for your learning algorithm.

13
00:00:28,040 --> 00:00:29,600
That case is the case

14
00:00:29,610 --> 00:00:32,600
of what's called skewed classes.

15
00:00:32,610 --> 00:00:34,980
Let me tell you what that means.

16
00:00:36,170 --> 00:00:38,170
Consider the problem of cancer

17
00:00:38,180 --> 00:00:40,290
classification, where we have

18
00:00:40,300 --> 00:00:42,060
features of medical patients and

19
00:00:42,070 --> 00:00:44,620
we want to decide whether or not they have cancer.

20
00:00:44,630 --> 00:00:46,340
So this is like the malignant

21
00:00:46,350 --> 00:00:48,920
versus benign tumor classification

22
00:00:48,930 --> 00:00:51,130
example that we had earlier.

23
00:00:51,140 --> 00:00:52,540
So let's say y equals 1 if the

24
00:00:52,550 --> 00:00:54,270
patient has cancer and y equals 0

25
00:00:54,280 --> 00:00:56,800
if they do not.

26
00:00:56,810 --> 00:00:57,930
We have trained the progression

27
00:00:57,940 --> 00:00:59,990
classifier and let's say

28
00:01:00,000 --> 00:01:01,650
we test our classifier on

29
00:01:01,660 --> 00:01:04,780
a test set and find that we get 1 percent error.

30
00:01:04,790 --> 00:01:06,520
So, we're making 99% correct diagnosis.

31
00:01:06,530 --> 00:01:09,900
Seems like a really impressive result, right.

32
00:01:09,910 --> 00:01:12,420
We're correct 99% percent of the time.

33
00:01:12,560 --> 00:01:13,930
But now, let's say we find

34
00:01:13,940 --> 00:01:16,500
out that only 0.5 percent

35
00:01:16,510 --> 00:01:18,150
of patients in our

36
00:01:18,160 --> 00:01:20,390
training test sets actually have cancer.

37
00:01:20,400 --> 00:01:21,940
So only half a

38
00:01:21,950 --> 00:01:23,570
percent of the patients that

39
00:01:23,580 --> 00:01:26,550
come through our screening process have cancer.

40
00:01:26,560 --> 00:01:28,260
In this case, the 1%

41
00:01:28,270 --> 00:01:31,120
error no longer looks so impressive.

42
00:01:31,130 --> 00:01:32,660
And in particular, here's a piece

43
00:01:32,670 --> 00:01:33,840
of code, here's actually a piece

44
00:01:33,850 --> 00:01:36,070
of non learning code that takes

45
00:01:36,080 --> 00:01:38,470
this input of features x and it ignores it.

46
00:01:38,480 --> 00:01:39,940
It just sets y equals 0

47
00:01:39,950 --> 00:01:41,710
and always predicts, you

48
00:01:41,720 --> 00:01:44,160
know, nobody has cancer and this

49
00:01:44,170 --> 00:01:45,990
algorithm would actually get

50
00:01:46,000 --> 00:01:48,820
0.5 percent error.

51
00:01:48,830 --> 00:01:50,390
So this is even better than

52
00:01:50,400 --> 00:01:51,230
the 1% error that we were getting just now

53
00:01:51,240 --> 00:01:53,150
and this is a non

54
00:01:53,160 --> 00:01:54,790
learning algorithm that you know, it is just

55
00:01:54,800 --> 00:01:57,980
predicting y equals 0 all the time.

56
00:01:57,990 --> 00:02:00,050
So this setting of when

57
00:02:00,060 --> 00:02:02,170
the ratio of positive to

58
00:02:02,180 --> 00:02:04,800
negative examples is very close

59
00:02:04,810 --> 00:02:07,030
to one of two extremes, where,

60
00:02:07,040 --> 00:02:08,700
in this case, the number of

61
00:02:08,710 --> 00:02:10,340
positive examples is much,

62
00:02:10,350 --> 00:02:11,610
much smaller than the number

63
00:02:11,620 --> 00:02:13,470
of negative examples because y

64
00:02:13,480 --> 00:02:15,720
equals one so rarely, this

65
00:02:15,730 --> 00:02:16,990
is what we call the

66
00:02:17,000 --> 00:02:20,100
case of skewed classes.

67
00:02:20,790 --> 00:02:21,990
We just have a lot more

68
00:02:22,000 --> 00:02:23,560
of examples from one class

69
00:02:23,570 --> 00:02:25,210
than from the other class.

70
00:02:25,220 --> 00:02:26,910
And by just predicting y equals

71
00:02:26,920 --> 00:02:28,640
0 all the time, or maybe

72
00:02:28,650 --> 00:02:29,780
our predicting y equals 1

73
00:02:29,790 --> 00:02:32,970
all the time, an algorithm can do pretty well.

74
00:02:32,980 --> 00:02:34,660
So the problem with using

75
00:02:34,670 --> 00:02:36,580
classification error or classification

76
00:02:36,590 --> 00:02:40,420
accuracy as our evaluation metric is the following.

77
00:02:40,430 --> 00:02:41,690
Let's say you have one joining

78
00:02:41,700 --> 00:02:45,070
algorithm that's getting 99.2% accuracy.

79
00:02:46,530 --> 00:02:47,320
So, that's a 0.8% error.

80
00:02:47,330 --> 00:02:50,990
Let's say you

81
00:02:51,000 --> 00:02:52,800
make a change to your algorithm

82
00:02:52,810 --> 00:02:54,270
and you now are getting

83
00:02:54,280 --> 00:02:57,580
99.5% accuracy.

84
00:02:59,280 --> 00:03:03,610
That is 0.5% error.

85
00:03:04,230 --> 00:03:06,760
So, is this an improvement to the algorithm or not?

86
00:03:06,770 --> 00:03:08,290
One of the nice things

87
00:03:08,300 --> 00:03:10,110
about having a single real

88
00:03:10,120 --> 00:03:11,640
number evaluation metric is this

89
00:03:11,650 --> 00:03:13,230
helps us to quickly decide if

90
00:03:13,240 --> 00:03:16,360
we just need a good change to the algorithm or not.

91
00:03:16,370 --> 00:03:21,420
By going from 99.2% accuracy to 99.5% accuracy.

92
00:03:21,430 --> 00:03:22,770
You know, did we just do something

93
00:03:22,780 --> 00:03:23,760
useful or did we

94
00:03:23,770 --> 00:03:25,310
just replace our code with

95
00:03:25,320 --> 00:03:26,990
something that just predicts y equals

96
00:03:27,000 --> 00:03:29,290
zero more often?

97
00:03:29,300 --> 00:03:31,330
So, if you have very skewed classes

98
00:03:31,340 --> 00:03:33,630
it becomes much harder to use

99
00:03:33,640 --> 00:03:36,110
just classification accuracy, because you

100
00:03:36,120 --> 00:03:38,410
can get very high classification accuracies

101
00:03:38,420 --> 00:03:41,100
or very low errors, and

102
00:03:41,110 --> 00:03:43,060
it's not always clear if

103
00:03:43,070 --> 00:03:44,760
doing so is really improving

104
00:03:44,770 --> 00:03:46,390
the quality of your classifier

105
00:03:46,400 --> 00:03:48,370
because predicting y equals 0 all the

106
00:03:48,380 --> 00:03:51,560
time doesn't seem like

107
00:03:51,570 --> 00:03:53,890
a particularly good classifier.

108
00:03:53,900 --> 00:03:55,710
But just predicting y equals 0 more

109
00:03:55,720 --> 00:03:57,820
often can bring your error

110
00:03:57,830 --> 00:03:59,640
down to, you know, maybe as

111
00:03:59,650 --> 00:04:01,480
low as 0.5%.

112
00:04:01,490 --> 00:04:02,760
When we're faced with such

113
00:04:02,770 --> 00:04:05,240
a skewed classes therefore we

114
00:04:05,250 --> 00:04:06,460
would want to come up

115
00:04:06,470 --> 00:04:08,310
with a different error metric

116
00:04:08,320 --> 00:04:10,280
or a different evaluation metric.

117
00:04:10,290 --> 00:04:12,860
One such evaluation metric are

118
00:04:12,870 --> 00:04:15,430
what's called precision recall.

119
00:04:15,440 --> 00:04:17,510
Let me explain what that is.

120
00:04:17,520 --> 00:04:20,740
Let's say we are evaluating a classifier on the test set.

121
00:04:20,750 --> 00:04:21,880
For the examples in the

122
00:04:21,890 --> 00:04:25,390
test set the actual

123
00:04:25,450 --> 00:04:27,310
class of that example

124
00:04:27,320 --> 00:04:28,540
in the test set is going to

125
00:04:28,550 --> 00:04:30,430
be either one or zero, right,

126
00:04:30,440 --> 00:04:33,860
if there is a binary classification problem.

127
00:04:33,870 --> 00:04:35,350
And what our learning algorithm

128
00:04:35,360 --> 00:04:37,920
will do is it will, you know,

129
00:04:37,930 --> 00:04:39,440
predict some value for the

130
00:04:39,450 --> 00:04:41,550
class and our learning

131
00:04:41,560 --> 00:04:43,750
algorithm will predict the value

132
00:04:43,760 --> 00:04:44,900
for each example in my

133
00:04:44,910 --> 00:04:46,910
test set and the predicted value

134
00:04:46,920 --> 00:04:50,040
will also be either one or zero.

135
00:04:50,050 --> 00:04:52,260
So let me draw a two

136
00:04:52,270 --> 00:04:53,900
by two table as follows,

137
00:04:53,910 --> 00:04:56,310
depending on a full of these entries

138
00:04:56,320 --> 00:04:57,950
depending on what was the

139
00:04:57,960 --> 00:05:00,210
actual class and what was the predicted class.

140
00:05:00,220 --> 00:05:01,560
If we have an

141
00:05:01,570 --> 00:05:02,960
example where the actual class is

142
00:05:02,970 --> 00:05:04,230
one and the predicted class

143
00:05:04,240 --> 00:05:07,610
is one then that's called

144
00:05:07,620 --> 00:05:08,930
an example that's a true

145
00:05:08,940 --> 00:05:10,720
positive, meaning our algorithm

146
00:05:10,730 --> 00:05:12,390
predicted that it's positive

147
00:05:12,400 --> 00:05:16,230
and in reality the example is positive.

148
00:05:16,240 --> 00:05:17,480
If our learning algorithm predicted that

149
00:05:17,490 --> 00:05:19,560
something is negative, class zero,

150
00:05:19,570 --> 00:05:20,960
and the actual class is also

151
00:05:20,970 --> 00:05:24,060
class zero then that's what's called a true negative.

152
00:05:24,070 --> 00:05:27,870
We predicted zero and it actually is zero.

153
00:05:27,880 --> 00:05:29,460
To find the other two boxes,

154
00:05:29,470 --> 00:05:31,350
if our learning algorithm predicts that

155
00:05:31,360 --> 00:05:34,330
the class is one but the

156
00:05:34,340 --> 00:05:36,660
actual class is zero, then

157
00:05:36,670 --> 00:05:39,340
that's called a false positive.

158
00:05:39,350 --> 00:05:40,820
So that means our algorithm for

159
00:05:40,830 --> 00:05:42,180
the patient is cancelled out in

160
00:05:42,190 --> 00:05:44,720
reality if the patient does not.

161
00:05:44,730 --> 00:05:48,190
And finally, the last box is a zero, one.

162
00:05:48,200 --> 00:05:51,170
That's called a false negative

163
00:05:51,180 --> 00:05:53,440
because our algorithm predicted

164
00:05:53,450 --> 00:05:57,220
zero, but the actual class was one.

165
00:05:57,230 --> 00:05:59,140
And so, we

166
00:05:59,150 --> 00:06:00,980
have this little sort of two by

167
00:06:00,990 --> 00:06:03,240
two table based on

168
00:06:03,250 --> 00:06:07,000
what was the actual class and what was the predicted class.

169
00:06:07,080 --> 00:06:08,680
So here's a different way

170
00:06:08,690 --> 00:06:10,410
of evaluating the performance of

171
00:06:10,420 --> 00:06:12,540
our algorithm. We're

172
00:06:12,550 --> 00:06:13,300
going to compute two numbers.

173
00:06:13,310 --> 00:06:14,930
The first is called precision -

174
00:06:14,940 --> 00:06:17,160
and what that says is,

175
00:06:17,170 --> 00:06:18,570
of all the patients where we've

176
00:06:18,580 --> 00:06:20,630
predicted that they have cancer,

177
00:06:20,640 --> 00:06:24,550
what fraction of them actually have cancer?

178
00:06:24,560 --> 00:06:26,010
So let me write this down,

179
00:06:26,020 --> 00:06:27,670
the precision of a classifier

180
00:06:27,680 --> 00:06:29,300
is the number of true

181
00:06:29,310 --> 00:06:32,930
positives divided by

182
00:06:32,940 --> 00:06:36,690
the number that we predicted

183
00:06:37,140 --> 00:06:38,870
as positive, right?

184
00:06:39,150 --> 00:06:41,080
So of all the patients that

185
00:06:41,090 --> 00:06:43,880
we went to those patients and we told them, "We think you have cancer."

186
00:06:43,890 --> 00:06:45,880
Of all those patients, what

187
00:06:45,890 --> 00:06:47,490
fraction of them actually have cancer?

188
00:06:47,500 --> 00:06:49,790
So that's called precision.

189
00:06:49,800 --> 00:06:50,940
And another way to write this

190
00:06:50,950 --> 00:06:55,000
would be true positives and

191
00:06:55,010 --> 00:06:56,660
then in the denominator is the

192
00:06:56,670 --> 00:06:59,200
number of predicted positives, and

193
00:06:59,210 --> 00:07:00,230
so that would be the

194
00:07:00,240 --> 00:07:02,400
sum of the, you know, entries

195
00:07:02,410 --> 00:07:04,710
in this first row of the table.

196
00:07:04,720 --> 00:07:08,660
So it would be true positives divided by true positives.

197
00:07:08,670 --> 00:07:11,210
I'm going to abbreviate positive

198
00:07:11,220 --> 00:07:13,120
as POS and then

199
00:07:13,130 --> 00:07:15,880
plus false positives, again

200
00:07:15,890 --> 00:07:20,020
abbreviating positive using POS.

201
00:07:20,030 --> 00:07:21,910
So that's called precision, and as you

202
00:07:21,920 --> 00:07:23,650
can tell high precision would be good.

203
00:07:23,660 --> 00:07:25,060
That means that all the patients

204
00:07:25,070 --> 00:07:27,500
that we went to and we said, "You know, we're very sorry.

205
00:07:27,510 --> 00:07:29,430
We think you have cancer," high precision

206
00:07:29,440 --> 00:07:31,970
means that of that group

207
00:07:31,980 --> 00:07:33,380
of patients most of them

208
00:07:33,390 --> 00:07:34,810
we had actually made accurate

209
00:07:34,820 --> 00:07:38,130
predictions on them and they do have cancer.

210
00:07:38,840 --> 00:07:40,430
The second number we're going to compute

211
00:07:40,440 --> 00:07:42,050
is called recall, and what

212
00:07:42,060 --> 00:07:44,470
recall say is, if all

213
00:07:44,480 --> 00:07:46,180
the patients in, let's say,

214
00:07:46,190 --> 00:07:47,610
in the test set or the

215
00:07:47,620 --> 00:07:48,950
cross-validation set, but if

216
00:07:48,960 --> 00:07:50,140
all the patients in the data

217
00:07:50,150 --> 00:07:52,660
set that actually have cancer,

218
00:07:52,670 --> 00:07:54,390
what fraction of them that

219
00:07:54,400 --> 00:07:56,940
we correctly detect as having cancer.

220
00:07:56,950 --> 00:07:58,080
So if all the patients have

221
00:07:58,090 --> 00:07:59,390
cancer, how many of them

222
00:07:59,400 --> 00:08:01,310
did we actually go to them

223
00:08:01,320 --> 00:08:05,350
and you know, correctly told them that we think they need treatment.

224
00:08:05,860 --> 00:08:07,350
So, writing this down,

225
00:08:07,360 --> 00:08:09,030
recall is defined as the

226
00:08:09,040 --> 00:08:12,460
number of positives, the number

227
00:08:12,470 --> 00:08:15,250
of true positives,

228
00:08:15,260 --> 00:08:16,510
meaning the number of people

229
00:08:16,520 --> 00:08:18,020
that have cancer and that

230
00:08:18,030 --> 00:08:20,300
we correctly predicted have cancer

231
00:08:20,310 --> 00:08:21,780
and we take that and divide

232
00:08:21,790 --> 00:08:23,730
that by, divide that by

233
00:08:23,740 --> 00:08:30,800
the number of actual positives,

234
00:08:31,200 --> 00:08:32,500
so this is the right

235
00:08:32,510 --> 00:08:35,840
number of actual positives of all the people that do have cancer.

236
00:08:35,850 --> 00:08:37,420
What fraction do we directly

237
00:08:37,430 --> 00:08:40,450
flag and you know, send the treatment.

238
00:08:40,560 --> 00:08:41,920
So, to rewrite this in

239
00:08:41,930 --> 00:08:44,200
a different form, the denominator would

240
00:08:44,210 --> 00:08:45,420
be the number of actual

241
00:08:45,430 --> 00:08:47,210
positives as you know, is the sum

242
00:08:47,220 --> 00:08:50,590
of the entries in this first column over here.

243
00:08:50,600 --> 00:08:52,150
And so writing things out differently,

244
00:08:52,160 --> 00:08:53,640
this is therefore, the number of

245
00:08:53,650 --> 00:08:58,620
true positives, divided by

246
00:08:59,010 --> 00:09:02,780
the number of true positives

247
00:09:02,790 --> 00:09:06,740
plus the number of

248
00:09:06,750 --> 00:09:09,190
false negatives.

249
00:09:09,570 --> 00:09:13,680
And so once again, having a high recall would be a good thing.

250
00:09:14,180 --> 00:09:15,920
So by computing precision and

251
00:09:15,930 --> 00:09:17,330
recall this will usually

252
00:09:17,340 --> 00:09:19,130
give us a better sense of

253
00:09:19,140 --> 00:09:21,610
how well our classifier is doing.

254
00:09:21,620 --> 00:09:23,320
And in particular if we have

255
00:09:23,330 --> 00:09:25,510
a learning algorithm that predicts

256
00:09:25,520 --> 00:09:27,180
y equals zero all

257
00:09:27,190 --> 00:09:28,450
the time, if it predicts no

258
00:09:28,460 --> 00:09:30,240
one has cancer, then this

259
00:09:30,250 --> 00:09:32,060
classifier will have a

260
00:09:32,070 --> 00:09:34,360
recall equal to zero,

261
00:09:34,370 --> 00:09:35,560
because there won't be any

262
00:09:35,570 --> 00:09:37,180
true positives and so that's

263
00:09:37,190 --> 00:09:38,000
a quick way for us to

264
00:09:38,010 --> 00:09:40,350
recognize that, you know, a

265
00:09:40,360 --> 00:09:42,040
classifier that predicts y equals 0 all the time,

266
00:09:42,050 --> 00:09:43,990
just isn't a very good classifier.

267
00:09:44,000 --> 00:09:47,440
And more generally,

268
00:09:47,450 --> 00:09:48,940
even for settings where we

269
00:09:48,950 --> 00:09:51,040
have very skewed classes, it's

270
00:09:51,050 --> 00:09:53,430
not possible for an

271
00:09:53,440 --> 00:09:55,440
algorithm to sort of "cheat"

272
00:09:55,450 --> 00:09:56,740
and somehow get a very

273
00:09:56,750 --> 00:09:58,000
high precision and a

274
00:09:58,010 --> 00:09:59,610
very high recall by doing

275
00:09:59,620 --> 00:10:01,040
some simple thing like predicting

276
00:10:01,050 --> 00:10:02,710
y equals 0 all the time or

277
00:10:02,720 --> 00:10:04,950
predicting y equals 1 all the time.

278
00:10:04,960 --> 00:10:06,670
And so we're much

279
00:10:06,680 --> 00:10:08,830
more sure that a classifier

280
00:10:08,840 --> 00:10:10,600
of a high precision or high recall

281
00:10:10,610 --> 00:10:12,460
actually is a good classifier,

282
00:10:12,470 --> 00:10:14,030
and this gives us a

283
00:10:14,040 --> 00:10:15,900
more useful evaluation metric that

284
00:10:15,910 --> 00:10:17,220
is a more direct way to

285
00:10:17,230 --> 00:10:21,670
actually understand whether, you know, our algorithm may be doing well.

286
00:10:21,680 --> 00:10:23,190
So one final note in

287
00:10:23,200 --> 00:10:25,140
the definition of precision and

288
00:10:25,150 --> 00:10:26,710
recall, that we would define

289
00:10:26,720 --> 00:10:29,090
precision and recall, usually we

290
00:10:29,100 --> 00:10:32,080
use the convention that y is equal to 1, in

291
00:10:32,090 --> 00:10:34,150
the presence of the more rare class.

292
00:10:34,160 --> 00:10:35,870
So if we are trying to detect.

293
00:10:35,880 --> 00:10:37,710
rare conditions such as cancer,

294
00:10:37,720 --> 00:10:39,330
hopefully that's a rare condition,

295
00:10:39,340 --> 00:10:40,990
precision and recall are

296
00:10:41,000 --> 00:10:42,780
defined setting y equals

297
00:10:42,790 --> 00:10:44,180
1, rather than y

298
00:10:44,190 --> 00:10:45,810
equals 0, to be sort of

299
00:10:45,820 --> 00:10:47,240
that the presence of that rare

300
00:10:47,250 --> 00:10:50,440
class that we're trying to detect.

301
00:10:50,450 --> 00:10:52,880
And by using precision and recall,

302
00:10:52,890 --> 00:10:54,380
we find, what happens is

303
00:10:54,390 --> 00:10:55,600
that even if we have

304
00:10:55,610 --> 00:10:57,580
very skewed classes, it's not

305
00:10:57,590 --> 00:10:59,590
possible for an algorithm to

306
00:10:59,600 --> 00:11:01,370
you know, "cheat" and predict

307
00:11:01,380 --> 00:11:02,750
y equals 1 all the time,

308
00:11:02,760 --> 00:11:03,970
or predict y equals 0 all

309
00:11:03,980 --> 00:11:06,630
the time, and get high precision and recall.

310
00:11:06,640 --> 00:11:08,470
And in particular, if a classifier

311
00:11:08,480 --> 00:11:09,870
is getting high precision and high

312
00:11:09,880 --> 00:11:11,260
recall, then we are

313
00:11:11,270 --> 00:11:13,580
actually confident that the algorithm

314
00:11:13,590 --> 00:11:15,390
has to be doing well, even

315
00:11:15,400 --> 00:11:18,020
if we have very skewed classes.

316
00:11:18,030 --> 00:11:20,940
So for the problem of skewed classes precision

317
00:11:20,950 --> 00:11:22,770
recall gives us more

318
00:11:22,780 --> 00:11:24,900
direct insight into how

319
00:11:24,910 --> 00:11:26,650
the learning algorithm is doing

320
00:11:26,660 --> 00:11:28,060
and this is often a much

321
00:11:28,070 --> 00:11:30,260
better way to evaluate our learning algorithms,

322
00:11:30,270 --> 00:11:32,500
than looking at classification error

323
00:11:32,510 --> 00:11:36,700
or classification accuracy, when the classes are very skewed.

