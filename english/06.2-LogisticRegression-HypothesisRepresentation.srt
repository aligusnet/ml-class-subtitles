1
00:00:00,210 --> 00:00:02,940
Let's start talking about logistic regression.

2
00:00:02,950 --> 00:00:04,250
In this video, I'd like to

3
00:00:04,260 --> 00:00:07,200
show you the hypothesis representation, that

4
00:00:07,210 --> 00:00:08,800
is, what is the function

5
00:00:08,810 --> 00:00:10,290
we're going to use to represent

6
00:00:10,300 --> 00:00:14,670
our hypothesis where we have a classification problem.

7
00:00:15,450 --> 00:00:16,920
Earlier, we said that we

8
00:00:16,930 --> 00:00:20,250
would like our classifier to

9
00:00:20,380 --> 00:00:21,910
output values that are between

10
00:00:21,920 --> 00:00:23,260
zero and one. So, we

11
00:00:23,270 --> 00:00:24,540
like to come up with a

12
00:00:24,550 --> 00:00:26,360
hypothesis that satisfies this

13
00:00:26,370 --> 00:00:30,340
property, that these predictions are maybe between zero and one.

14
00:00:30,350 --> 00:00:32,720
When we were using linear regression,

15
00:00:32,730 --> 00:00:34,250
this was the form of a

16
00:00:34,260 --> 00:00:35,580
hypothesis, where H of X

17
00:00:35,590 --> 00:00:38,320
is theta transpose X.  For

18
00:00:38,330 --> 00:00:39,740
logistic regression, I'm going

19
00:00:39,750 --> 00:00:41,040
to modify this a little

20
00:00:41,050 --> 00:00:43,350
bit, and make the hypothesis

21
00:00:43,360 --> 00:00:46,190
G of theta transpose X,

22
00:00:46,200 --> 00:00:47,590
where I'm going to define

23
00:00:47,600 --> 00:00:50,670
the function G as follows:

24
00:00:50,680 --> 00:00:51,900
G of Z if Z

25
00:00:51,910 --> 00:00:53,630
is a real number is equal

26
00:00:53,640 --> 00:00:55,620
to one over one plus

27
00:00:55,630 --> 00:00:58,480
E to the negative Z. This

28
00:00:58,490 --> 00:01:01,710
called the sigmoid function

29
00:01:01,720 --> 00:01:04,830
or the logistic function.

30
00:01:04,840 --> 00:01:07,110
And the term logistic function,

31
00:01:07,120 --> 00:01:11,080
that's what give rise to the name logistic progression.

32
00:01:11,100 --> 00:01:12,740
And, by the way, the terms

33
00:01:12,750 --> 00:01:14,540
sigmoid function and logistic

34
00:01:14,550 --> 00:01:16,930
function are basically synonyms

35
00:01:16,940 --> 00:01:18,290
and mean the same thing.

36
00:01:18,300 --> 00:01:19,720
So the two terms are

37
00:01:19,730 --> 00:01:21,870
basically interchangeable and either

38
00:01:21,880 --> 00:01:23,090
term can be used to

39
00:01:23,100 --> 00:01:24,600
refer to this function

40
00:01:24,610 --> 00:01:26,270
G.

And if we

41
00:01:26,280 --> 00:01:27,710
take these two equations, and

42
00:01:27,720 --> 00:01:30,070
put them together, then here's

43
00:01:30,080 --> 00:01:32,340
just an alternative way of

44
00:01:32,350 --> 00:01:34,830
writing out the form of my hypothesis.

45
00:01:34,840 --> 00:01:36,530
I'm saying that H of x

46
00:01:36,540 --> 00:01:38,890
is one over one plus

47
00:01:38,900 --> 00:01:41,740
E to the negative theta transpose

48
00:01:41,750 --> 00:01:43,080
X, and all I've done is

49
00:01:43,090 --> 00:01:45,320
I've taken the variable

50
00:01:45,330 --> 00:01:46,750
Z, Z here's a

51
00:01:46,760 --> 00:01:48,160
real number and plugged in

52
00:01:48,170 --> 00:01:50,190
theta transpose X, so

53
00:01:50,200 --> 00:01:52,550
I end up with, you know, theta transpose

54
00:01:52,560 --> 00:01:54,930
X, in place of Z there.

55
00:01:54,940 --> 00:01:57,900
Lastly, let me show you where the sigmoid function looks like.

56
00:01:57,910 --> 00:02:00,270
We're going to plot it on this figure here.

57
00:02:00,280 --> 00:02:02,000
The sigmoid function, G of

58
00:02:02,010 --> 00:02:04,620
Z, also called the logistic function, looks like this.

59
00:02:04,630 --> 00:02:07,040
It starts off near zero and

60
00:02:07,050 --> 00:02:09,350
then rises until it processes

61
00:02:09,360 --> 00:02:13,490
0.5 at the origin and then it flattens out again like so.

62
00:02:13,500 --> 00:02:16,020
So that's what the sigmoid function looks like.

63
00:02:16,030 --> 00:02:17,860
And you notice that the

64
00:02:17,870 --> 00:02:19,730
sigmoid function, well, it

65
00:02:19,740 --> 00:02:21,840
asymptotes at one, and

66
00:02:21,850 --> 00:02:24,240
asymptotes at zero as

67
00:02:24,250 --> 00:02:26,370
Z against the horizontal axis

68
00:02:26,380 --> 00:02:27,580
is Z. As Z goes to

69
00:02:27,590 --> 00:02:29,270
minus infinity, G of

70
00:02:29,280 --> 00:02:31,380
Z approaches zero and as

71
00:02:31,390 --> 00:02:33,740
G of Z approaches infinity, G

72
00:02:33,750 --> 00:02:35,870
of Z approaches 1, and

73
00:02:35,880 --> 00:02:37,230
so because G of

74
00:02:37,240 --> 00:02:39,360
Z offers values that are

75
00:02:39,370 --> 00:02:41,720
between 0 and 1 we

76
00:02:41,730 --> 00:02:44,600
also have that H of

77
00:02:44,610 --> 00:02:47,110
X must be between 0 and 1.

78
00:02:47,120 --> 00:02:50,030
Finally, given this hypothesis

79
00:02:50,040 --> 00:02:52,090
representation, what we

80
00:02:52,100 --> 00:02:53,710
need to do, as before,

81
00:02:53,720 --> 00:02:59,160
is fit the parameters theta to our data.

82
00:02:59,170 --> 00:03:00,410
So given a training set, we

83
00:03:00,420 --> 00:03:01,720
need to pick a value for

84
00:03:01,730 --> 00:03:03,730
the parameters theta and this

85
00:03:03,740 --> 00:03:06,970
hypothesis will then let us make predictions.

86
00:03:06,980 --> 00:03:08,520
We'll talk about a learning algorithm

87
00:03:08,530 --> 00:03:11,790
later for fitting the parameters theta.

88
00:03:11,800 --> 00:03:13,460
But first let's talk a

89
00:03:13,470 --> 00:03:17,340
bit about the interpretation of this model.

90
00:03:18,610 --> 00:03:19,610
Here's how I'm going to

91
00:03:19,620 --> 00:03:21,600
interpret the output of

92
00:03:21,610 --> 00:03:23,610
my hypothesis H of

93
00:03:23,620 --> 00:03:26,390
X.  When my hypothesis

94
00:03:26,400 --> 00:03:28,230
outputs some number, I am

95
00:03:28,240 --> 00:03:30,050
going to treat that number as

96
00:03:30,060 --> 00:03:33,370
the estimated probability that Y

97
00:03:33,380 --> 00:03:35,090
is equal to one on a

98
00:03:35,100 --> 00:03:38,580
new input example X. Here is what I mean.

99
00:03:38,590 --> 00:03:40,270
Here is an example.

100
00:03:40,280 --> 00:03:43,910
Let's say we're using the tumor classification example.

101
00:03:43,920 --> 00:03:45,180
So we may have a feature

102
00:03:45,190 --> 00:03:47,930
vector X, which is this x01

103
00:03:47,940 --> 00:03:49,790
as always and then our

104
00:03:49,800 --> 00:03:52,820
one feature is the size of the tumor.

105
00:03:52,830 --> 00:03:54,000
Suppose I have a patient come

106
00:03:54,010 --> 00:03:55,410
in and, you know they have some

107
00:03:55,420 --> 00:03:57,140
tumor size and I

108
00:03:57,150 --> 00:03:58,720
feed their feature vector X

109
00:03:58,730 --> 00:04:00,960
into my hypothesis and suppose

110
00:04:00,970 --> 00:04:03,710
my hypothesis outputs the number 0.7.

111
00:04:03,720 --> 00:04:05,720
I'm going to interpret

112
00:04:05,730 --> 00:04:07,280
my hypothesis as follows.

113
00:04:07,290 --> 00:04:08,760
I'm going to say that this

114
00:04:08,770 --> 00:04:10,220
hypothesis is telling me

115
00:04:10,230 --> 00:04:12,110
that for a patient with

116
00:04:12,120 --> 00:04:14,510
features X, the probability

117
00:04:14,520 --> 00:04:16,740
that Y equals one is 0  .7.

118
00:04:16,750 --> 00:04:18,710
In other words, I'm going

119
00:04:18,720 --> 00:04:21,050
to tell my patient that the

120
00:04:21,060 --> 00:04:24,300
tumor, sadly, has

121
00:04:24,310 --> 00:04:27,660
a 70% chance or a 0.7 chance of being malignant.

122
00:04:27,860 --> 00:04:29,370
To write this out slightly more

123
00:04:29,380 --> 00:04:30,470
formally or to write this

124
00:04:30,480 --> 00:04:31,730
out in math, I'm going to

125
00:04:31,740 --> 00:04:34,810
interpret my hypothesis output

126
00:04:34,820 --> 00:04:37,140
as P of y

127
00:04:37,150 --> 00:04:39,890
equals 1, given X

128
00:04:39,900 --> 00:04:41,820
parametrized by theta.

129
00:04:41,830 --> 00:04:43,270
So, for those of you that are

130
00:04:43,280 --> 00:04:45,300
familiar with probability, this equation

131
00:04:45,310 --> 00:04:46,720
might make sense, if you're a little less familiar

132
00:04:46,730 --> 00:04:48,630
with probability, you know, here's

133
00:04:48,640 --> 00:04:51,570
how I read this expression, this

134
00:04:51,580 --> 00:04:53,130
is the probability that y is

135
00:04:53,140 --> 00:04:54,960
equals to one, given x

136
00:04:54,970 --> 00:04:56,470
instead of given that my patient

137
00:04:56,480 --> 00:04:58,030
has, you know, features X.

138
00:04:58,040 --> 00:04:59,820
Given my patient has a particular

139
00:04:59,830 --> 00:05:01,510
tumor size represented by my

140
00:05:01,520 --> 00:05:03,130
features X, and this

141
00:05:03,140 --> 00:05:07,120
probability is parametrized by theta.

142
00:05:07,130 --> 00:05:09,090
So I'm basically going to count

143
00:05:09,100 --> 00:05:10,940
on my hypothesis to give

144
00:05:10,950 --> 00:05:13,280
me estimates of the probability

145
00:05:13,290 --> 00:05:15,300
that Y is equal to 1.

146
00:05:15,310 --> 00:05:16,470
Now since this is a

147
00:05:16,480 --> 00:05:18,630
classification task, we know

148
00:05:18,640 --> 00:05:21,470
that Y must be either zero or one, right?

149
00:05:21,480 --> 00:05:23,380
Those are the only two values

150
00:05:23,390 --> 00:05:25,280
that Y could possibly take on,

151
00:05:25,290 --> 00:05:26,620
either in the training set or

152
00:05:26,630 --> 00:05:28,060
for new patients that may walk

153
00:05:28,070 --> 00:05:32,100
into my office or into the doctor's office in the future.

154
00:05:32,320 --> 00:05:33,540
So given H of X,

155
00:05:33,550 --> 00:05:36,120
we can therefore compute the probability

156
00:05:36,130 --> 00:05:39,060
that Y is equal to zero as well.

157
00:05:39,070 --> 00:05:41,240
Concretely, because Y must

158
00:05:41,250 --> 00:05:43,060
be either zero or one,

159
00:05:43,070 --> 00:05:45,110
we know that the probability

160
00:05:45,120 --> 00:05:46,240
of Y equals zero, plus the

161
00:05:46,250 --> 00:05:47,540
probability of Y equals

162
00:05:47,550 --> 00:05:50,240
one, must add up to one.

163
00:05:50,250 --> 00:05:51,450
This first equation looks a

164
00:05:51,460 --> 00:05:52,770
little bit more complicated but it's

165
00:05:52,780 --> 00:05:54,600
basically saying that probability of

166
00:05:54,610 --> 00:05:56,310
Y equals zero for a

167
00:05:56,320 --> 00:05:58,350
particular patient with features x, and

168
00:05:58,360 --> 00:06:01,000
you know, given our parameter's data, plus the

169
00:06:01,010 --> 00:06:02,280
probability of Y equals one for

170
00:06:02,290 --> 00:06:04,430
that same patient which features x and you

171
00:06:04,440 --> 00:06:06,350
parameters theta must add

172
00:06:06,360 --> 00:06:08,240
up to one, if this equation

173
00:06:08,250 --> 00:06:10,190
looks a little bit complicated feel free

174
00:06:10,200 --> 00:06:14,270
to mentally imagine it without that X and theta.

175
00:06:14,280 --> 00:06:15,470
And this is just saying that

176
00:06:15,480 --> 00:06:16,910
the probability of Y equals zero plus

177
00:06:16,920 --> 00:06:19,270
the probability of Y equals one must be equal to one.

178
00:06:19,280 --> 00:06:20,230
And we know this to be

179
00:06:20,240 --> 00:06:23,080
true because Y has to be either zero or one.

180
00:06:23,090 --> 00:06:24,200
And so the chance of Y

181
00:06:24,210 --> 00:06:25,920
being zero plus the chance

182
00:06:25,930 --> 00:06:29,530
that Y is one, you know, those two must add up to one.

183
00:06:29,540 --> 00:06:31,430
And so if you just

184
00:06:31,440 --> 00:06:33,750
take this term and move

185
00:06:33,760 --> 00:06:35,390
it to the right-hand side, then

186
00:06:35,400 --> 00:06:37,290
you end up with this equation

187
00:06:37,300 --> 00:06:38,950
that says probability Y equals zero

188
00:06:38,960 --> 00:06:40,520
is one minus probability y equals

189
00:06:40,530 --> 00:06:43,550
and thus if our

190
00:06:43,560 --> 00:06:45,950
hypothesis if H of X

191
00:06:45,960 --> 00:06:47,780
gives us that term you can

192
00:06:47,790 --> 00:06:49,880
therefore quite simply compute the

193
00:06:49,890 --> 00:06:51,500
probability, or compute the

194
00:06:51,510 --> 00:06:53,240
estimated probability that Y

195
00:06:53,250 --> 00:06:55,310
is equal to zero as well.

196
00:06:55,320 --> 00:06:56,630
So you now know what

197
00:06:56,640 --> 00:06:59,780
the hypothesis representation is for

198
00:06:59,790 --> 00:07:01,570
logistic regression and we're seeing

199
00:07:01,580 --> 00:07:03,500
what the mathematical formula is

200
00:07:03,510 --> 00:07:06,620
defining the hypothesis for logistic regression.

201
00:07:06,630 --> 00:07:07,870
In the next video, I'd like

202
00:07:07,880 --> 00:07:09,030
to try to give you

203
00:07:09,040 --> 00:07:11,040
better intuition about what the

204
00:07:11,050 --> 00:07:12,480
hypothesis function looks like.

205
00:07:12,490 --> 00:07:13,610
And I want to tell

206
00:07:13,620 --> 00:07:15,200
you something called the decision

207
00:07:15,210 --> 00:07:16,650
boundary and we'll look

208
00:07:16,660 --> 00:07:18,830
at some visualizations together to

209
00:07:18,840 --> 00:07:20,130
try to get a better sense

210
00:07:20,140 --> 00:07:22,350
of what this hypothesis function of

211
00:07:22,360 --> 00:07:25,260
logistic regression really looks like.

