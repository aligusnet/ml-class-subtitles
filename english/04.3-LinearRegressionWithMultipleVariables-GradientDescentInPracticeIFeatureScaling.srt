1
00:00:00,190 --> 00:00:01,430
In this video and in

2
00:00:01,440 --> 00:00:02,840
the video after this one, I

3
00:00:02,850 --> 00:00:04,170
wanna tell you about some of

4
00:00:04,180 --> 00:00:07,670
the practical tricks for making gradient descent work well.

5
00:00:07,680 --> 00:00:11,750
In this video, I want to tell you about an idea called feature scale.

6
00:00:11,770 --> 00:00:13,020
Here's the idea.

7
00:00:13,030 --> 00:00:14,170
If you have a problem where you

8
00:00:14,180 --> 00:00:16,310
have multiple features, if you

9
00:00:16,320 --> 00:00:18,040
make sure that the features

10
00:00:18,050 --> 00:00:19,560
are on a similar scale, by

11
00:00:19,570 --> 00:00:20,640
which I mean make sure that

12
00:00:20,650 --> 00:00:22,290
the different features take on

13
00:00:22,300 --> 00:00:24,410
similar ranges of values,

14
00:00:24,420 --> 00:00:27,500
then gradient descents can converge more quickly.

15
00:00:27,510 --> 00:00:28,810
Concretely let's say you

16
00:00:28,820 --> 00:00:30,370
have a problem with two features

17
00:00:30,380 --> 00:00:31,940
where X1 is the size

18
00:00:31,950 --> 00:00:33,520
of house and takes on values

19
00:00:33,530 --> 00:00:35,480
between say zero to two thousand

20
00:00:35,490 --> 00:00:36,510
and two is the number

21
00:00:36,520 --> 00:00:37,810
of bedrooms, and maybe that takes

22
00:00:37,820 --> 00:00:40,090
on values between one and five.

23
00:00:40,100 --> 00:00:41,790
If you plot the contours of

24
00:00:41,800 --> 00:00:44,500
the cost function J of theta,

25
00:00:44,810 --> 00:00:46,740
then the contours may look

26
00:00:46,750 --> 00:00:49,220
like this, where, let's see,

27
00:00:49,230 --> 00:00:50,900
J of theta is a function

28
00:00:50,910 --> 00:00:54,290
of parameters theta zero, theta one and theta two.

29
00:00:54,300 --> 00:00:56,010
I'm going to ignore theta zero,

30
00:00:56,020 --> 00:00:57,470
so let's forget about theta 0

31
00:00:57,480 --> 00:00:58,830
and pretend it's a function of

32
00:00:58,840 --> 00:01:01,500
only theta 1 and theta

33
00:01:01,510 --> 00:01:02,930
2, but if x1 can take on

34
00:01:02,940 --> 00:01:04,360
them, you know, much larger range

35
00:01:04,370 --> 00:01:06,110
of values and x2 It turns

36
00:01:06,120 --> 00:01:07,330
out that the contours of the

37
00:01:07,340 --> 00:01:09,410
cost function J of theta

38
00:01:09,420 --> 00:01:11,680
can take on this very

39
00:01:11,690 --> 00:01:15,060
very skewed elliptical shape, except

40
00:01:15,070 --> 00:01:16,760
that with the 2000 to

41
00:01:16,770 --> 00:01:18,790
5 ratio, it can be even more skewed.

42
00:01:18,800 --> 00:01:20,550
So, this is very, very tall

43
00:01:20,560 --> 00:01:23,310
and skinny ellipses, or these

44
00:01:23,320 --> 00:01:25,300
very tall skinny ovals, can form

45
00:01:25,310 --> 00:01:29,410
the contours of the cost function J of theta.

46
00:01:29,420 --> 00:01:30,920
And if you run gradient descents

47
00:01:30,930 --> 00:01:34,820
on this cost-function, your

48
00:01:34,830 --> 00:01:36,960
gradients may end up

49
00:01:36,970 --> 00:01:39,070
taking a long time and

50
00:01:39,080 --> 00:01:41,090
can oscillate back and forth

51
00:01:41,100 --> 00:01:43,180
and take a long time before it

52
00:01:43,190 --> 00:01:47,460
can finally find its way to the global minimum.

53
00:01:47,470 --> 00:01:48,880
In fact, you can imagine if these

54
00:01:48,890 --> 00:01:50,570
contours are exaggerated even

55
00:01:50,580 --> 00:01:52,470
more when you draw incredibly

56
00:01:52,480 --> 00:01:55,800
skinny, tall skinny contours,

57
00:01:56,230 --> 00:01:57,370
and it can be even more extreme

58
00:01:57,380 --> 00:01:59,780
than, then, gradient descent

59
00:01:59,790 --> 00:02:02,620
just have a much

60
00:02:02,630 --> 00:02:04,680
harder time taking it's way,

61
00:02:04,690 --> 00:02:06,110
meandering around, it can take

62
00:02:06,120 --> 00:02:09,770
a long time to find this way to the global minimum.

63
00:02:12,130 --> 00:02:14,770
In these settings, a useful

64
00:02:14,780 --> 00:02:17,370
thing to do is to scale the features.

65
00:02:17,380 --> 00:02:19,190
Concretely if you instead

66
00:02:19,200 --> 00:02:20,560
define the feature X

67
00:02:20,570 --> 00:02:21,860
one to be the size of

68
00:02:21,870 --> 00:02:24,030
the house divided by two thousand,

69
00:02:24,040 --> 00:02:25,260
and define X two to be

70
00:02:25,270 --> 00:02:26,930
maybe the number of bedrooms divided

71
00:02:26,940 --> 00:02:29,160
by five, then the

72
00:02:29,170 --> 00:02:30,080
countours of the

73
00:02:30,090 --> 00:02:32,890
cost function J can become

74
00:02:32,900 --> 00:02:34,830
much more, much less

75
00:02:34,840 --> 00:02:38,200
skewed so the contours may look more like circles.

76
00:02:38,210 --> 00:02:39,510
And if you run gradient

77
00:02:39,520 --> 00:02:40,740
descent on a cost function like

78
00:02:40,750 --> 00:02:43,620
this, then gradient descent,

79
00:02:44,110 --> 00:02:45,850
you can show mathematically, you can

80
00:02:45,860 --> 00:02:47,530
find a much more direct path

81
00:02:47,540 --> 00:02:49,380
to the global minimum rather than taking

82
00:02:49,390 --> 00:02:51,520
a much more convoluted path

83
00:02:51,530 --> 00:02:52,610
where you're sort of trying to

84
00:02:52,620 --> 00:02:54,300
follow a much more complicated

85
00:02:54,310 --> 00:02:57,290
trajectory to get to the global minimum.

86
00:02:57,300 --> 00:02:58,940
So, by scaling the features so

87
00:02:58,950 --> 00:03:01,610
that there are similar ranges of values.

88
00:03:01,620 --> 00:03:02,960
In this example, we end up

89
00:03:02,970 --> 00:03:04,290
with both features, X one

90
00:03:04,300 --> 00:03:08,460
and X two, between zero and one.

91
00:03:09,580 --> 00:03:12,680
You can wind up with an implementation of gradient descent.

92
00:03:12,690 --> 00:03:15,310
that can convert much faster.

93
00:03:18,120 --> 00:03:20,150
More generally, when we're performing

94
00:03:20,160 --> 00:03:21,520
feature scaling, what we often

95
00:03:21,530 --> 00:03:22,740
want to do is get every

96
00:03:22,750 --> 00:03:25,770
feature into approximately a  -1

97
00:03:25,780 --> 00:03:28,950
to +1 range and concretely,

98
00:03:28,960 --> 00:03:31,750
your feature x0 is always equal to 1.

99
00:03:31,760 --> 00:03:34,100
So, that's already in that range,

100
00:03:34,110 --> 00:03:35,620
but you may end up dividing

101
00:03:35,630 --> 00:03:37,320
other features by different numbers

102
00:03:37,330 --> 00:03:39,500
to get them to this range.

103
00:03:39,510 --> 00:03:42,260
The numbers -1 and +1 aren't too important.

104
00:03:42,270 --> 00:03:44,140
So, if you have a feature,

105
00:03:44,150 --> 00:03:45,500
x1 that winds up

106
00:03:45,510 --> 00:03:48,390
being between zero and three, that's not a problem.

107
00:03:48,400 --> 00:03:49,590
If you end up having a different

108
00:03:49,600 --> 00:03:52,130
feature that winds being

109
00:03:52,140 --> 00:03:54,290
between -2 and  + 0.5,

110
00:03:54,300 --> 00:03:56,060
again, this is close enough

111
00:03:56,070 --> 00:03:57,310
to minus one and plus one

112
00:03:57,320 --> 00:04:00,300
that, you know, that's fine, and that's fine.

113
00:04:00,310 --> 00:04:01,330
It's only if you have a

114
00:04:01,340 --> 00:04:02,810
different feature, say X 3

115
00:04:02,820 --> 00:04:05,830
that is between, say, that

116
00:04:05,840 --> 00:04:09,320
ranges from -100 to +100

117
00:04:09,330 --> 00:04:11,080
, then, this is a

118
00:04:11,090 --> 00:04:13,850
very different values than minus 1 and plus 1.

119
00:04:13,860 --> 00:04:15,220
So, this might be a

120
00:04:15,230 --> 00:04:17,960
less well-scaled feature and similarly,

121
00:04:17,970 --> 00:04:19,410
if your features take on a

122
00:04:19,420 --> 00:04:20,940
very, very small range of

123
00:04:20,950 --> 00:04:22,330
values so if X 4

124
00:04:22,340 --> 00:04:25,730
takes on values between minus

125
00:04:25,740 --> 00:04:29,710
0.0001 and positive 0.0001, then

126
00:04:29,720 --> 00:04:30,900
again this takes on a

127
00:04:30,910 --> 00:04:32,450
much smaller range of values

128
00:04:32,460 --> 00:04:34,030
than the minus one to plus one range.

129
00:04:34,040 --> 00:04:37,840
And again I would consider this feature poorly scaled.

130
00:04:37,850 --> 00:04:39,420
So you want the range of

131
00:04:39,430 --> 00:04:41,060
values, you know, can be

132
00:04:41,070 --> 00:04:42,360
bigger than plus one or smaller

133
00:04:42,370 --> 00:04:44,030
than plus one, but just

134
00:04:44,040 --> 00:04:45,600
not much bigger, like plus

135
00:04:45,610 --> 00:04:47,640
100 here, or too

136
00:04:47,650 --> 00:04:50,760
much smaller like 0.001 one over there.

137
00:04:50,770 --> 00:04:52,860
Different people have different rules of thumb.

138
00:04:52,870 --> 00:04:54,060
But the one that I use is

139
00:04:54,070 --> 00:04:55,660
that if a feature takes

140
00:04:55,670 --> 00:04:56,970
on the range of values from

141
00:04:56,980 --> 00:04:58,830
say minus three to plus

142
00:04:58,840 --> 00:05:00,160
3 how you should think that should

143
00:05:00,170 --> 00:05:01,990
be just fine, but maybe

144
00:05:02,000 --> 00:05:03,430
it takes on much larger values

145
00:05:03,440 --> 00:05:04,520
than plus 3 or minus 3

146
00:05:04,530 --> 00:05:06,690
I tend not to worry and if

147
00:05:06,700 --> 00:05:10,910
it takes on values from say minus one-third to one-third.

148
00:05:10,920 --> 00:05:12,260
You know, I think that's fine

149
00:05:12,270 --> 00:05:14,900
too or 0 to one-third or minus one-third to 0.

150
00:05:14,910 --> 00:05:18,550
I guess that's typical range of value sector 0 okay.

151
00:05:18,560 --> 00:05:19,440
But it will take on a

152
00:05:19,450 --> 00:05:20,890
much tinier range of values

153
00:05:20,900 --> 00:05:23,780
like x4 here than gain on mine not to worry.

154
00:05:23,790 --> 00:05:25,490
So, the take-home message

155
00:05:25,500 --> 00:05:26,990
is don't worry if your

156
00:05:27,000 --> 00:05:28,690
features are not exactly on

157
00:05:28,700 --> 00:05:31,160
the same scale or exactly in the same range of values.

158
00:05:31,170 --> 00:05:32,080
But so long as they're all

159
00:05:32,090 --> 00:05:35,920
close enough to this gradient descent it should work okay.

160
00:05:35,930 --> 00:05:37,920
In addition to dividing by

161
00:05:37,930 --> 00:05:40,210
so that the maximum value when

162
00:05:40,220 --> 00:05:42,720
performing feature scaling sometimes

163
00:05:42,730 --> 00:05:45,320
people will also do what's called mean normalization.

164
00:05:45,330 --> 00:05:47,310
And what I mean by

165
00:05:47,320 --> 00:05:48,340
that is that you want

166
00:05:48,350 --> 00:05:50,220
to take a feature Xi and replace

167
00:05:50,230 --> 00:05:52,860
it with Xi minus mu i

168
00:05:52,870 --> 00:05:56,520
to make your features have approximately 0 mean.

169
00:05:56,530 --> 00:05:57,880
And obviously we want

170
00:05:57,890 --> 00:05:59,640
to apply this to the feature

171
00:05:59,650 --> 00:06:00,930
x zero, because the feature

172
00:06:00,940 --> 00:06:02,350
x zero is always equal to

173
00:06:02,360 --> 00:06:03,800
one, so it cannot have an

174
00:06:03,810 --> 00:06:06,360
average value of zero.

175
00:06:06,370 --> 00:06:07,940
But it concretely for other

176
00:06:07,950 --> 00:06:09,590
features if the range

177
00:06:09,600 --> 00:06:10,950
of sizes of the house

178
00:06:10,960 --> 00:06:14,300
takes on values between 0

179
00:06:14,310 --> 00:06:15,220
to 2000 and if you know,

180
00:06:15,230 --> 00:06:16,460
the average size of a

181
00:06:16,470 --> 00:06:18,490
house is equal to

182
00:06:18,500 --> 00:06:21,460
1000 then you might

183
00:06:21,470 --> 00:06:23,450
use this formula.

184
00:06:23,940 --> 00:06:25,240
Size, set the feature

185
00:06:25,250 --> 00:06:26,580
X1 to the size minus

186
00:06:26,590 --> 00:06:28,620
the average value divided by 2000

187
00:06:28,630 --> 00:06:32,520
and similarly, on average

188
00:06:32,530 --> 00:06:34,510
if your houses have

189
00:06:34,520 --> 00:06:39,130
one to five bedrooms and if

190
00:06:39,240 --> 00:06:40,880
on average a house has

191
00:06:40,890 --> 00:06:42,100
two bedrooms then you might

192
00:06:42,110 --> 00:06:45,070
use this formula to mean

193
00:06:45,080 --> 00:06:48,960
normalize the second feature x2.

194
00:06:49,340 --> 00:06:50,830
In both of these cases, you

195
00:06:50,840 --> 00:06:52,920
therefore wind up with features x1 and x2.

196
00:06:52,930 --> 00:06:54,870
They can take on values roughly

197
00:06:54,880 --> 00:06:57,120
between minus .5 and positive .5.

198
00:06:57,130 --> 00:06:58,200
Exactly not true - X2

199
00:06:58,210 --> 00:07:01,790
can actually be slightly larger than .5 but, close enough.

200
00:07:01,800 --> 00:07:03,520
And the more general rule is

201
00:07:03,530 --> 00:07:04,890
that you might take a

202
00:07:04,900 --> 00:07:07,890
feature X1 and replace

203
00:07:08,060 --> 00:07:10,930
it with X1 minus mu1

204
00:07:10,940 --> 00:07:13,540
over S1 where to

205
00:07:13,550 --> 00:07:16,190
define these terms mu1 is

206
00:07:16,200 --> 00:07:19,790
the average value of x1

207
00:07:19,960 --> 00:07:22,310
in the training sets

208
00:07:22,320 --> 00:07:24,340
and S1 is the

209
00:07:24,350 --> 00:07:27,810
range of values of that

210
00:07:27,820 --> 00:07:29,030
feature and by range, I

211
00:07:29,040 --> 00:07:30,620
mean let's say the maximum

212
00:07:30,630 --> 00:07:32,280
value minus the minimum

213
00:07:32,290 --> 00:07:33,580
value or for those

214
00:07:33,590 --> 00:07:35,840
of you that know the standard  deviation

215
00:07:35,850 --> 00:07:37,750
of the variable is setting S1

216
00:07:37,760 --> 00:07:41,010
to be the standard deviation of the variable would be fine, too.

217
00:07:41,020 --> 00:07:44,320
But taking, you know, this max minus min would be fine.

218
00:07:44,330 --> 00:07:45,600
And similarly for the second

219
00:07:45,610 --> 00:07:47,830
feature, x2, you replace

220
00:07:47,840 --> 00:07:51,030
x2 with this sort of

221
00:07:51,040 --> 00:07:52,790
subtract the mean of the feature

222
00:07:52,800 --> 00:07:54,370
and divide it by the range

223
00:07:54,380 --> 00:07:56,870
of values meaning the max minus min.

224
00:07:56,880 --> 00:07:58,360
And this sort of formula will

225
00:07:58,370 --> 00:07:59,840
get your features, you know, maybe

226
00:07:59,850 --> 00:08:01,910
not exactly, but maybe roughly

227
00:08:01,920 --> 00:08:03,480
into these sorts of

228
00:08:03,490 --> 00:08:04,880
ranges, and by the

229
00:08:04,890 --> 00:08:05,930
way, for those of you that

230
00:08:05,940 --> 00:08:07,700
are being super careful technically if

231
00:08:07,710 --> 00:08:09,600
we're taking the range as max

232
00:08:09,610 --> 00:08:13,130
minus min this five here will actually become a four.

233
00:08:13,140 --> 00:08:14,590
So if max is 5

234
00:08:14,600 --> 00:08:16,310
minus 1 then the range of

235
00:08:16,320 --> 00:08:17,850
their own values is actually

236
00:08:17,860 --> 00:08:18,680
equal to 4, but all of these

237
00:08:18,690 --> 00:08:20,820
are approximate and any value

238
00:08:20,830 --> 00:08:22,440
that gets the features into

239
00:08:22,450 --> 00:08:25,190
anything close to these sorts of ranges will do fine.

240
00:08:25,200 --> 00:08:27,650
And the feature scaling

241
00:08:27,660 --> 00:08:29,040
doesn't have to be too exact,

242
00:08:29,050 --> 00:08:30,780
in order to get gradient

243
00:08:30,790 --> 00:08:33,790
descent to run quite a lot faster.

244
00:08:34,610 --> 00:08:36,010
So, now you know

245
00:08:36,020 --> 00:08:37,520
about feature scaling and if

246
00:08:37,530 --> 00:08:39,240
you apply this simple trick, it

247
00:08:39,250 --> 00:08:40,860
can make gradient descent run much

248
00:08:40,870 --> 00:08:44,980
faster and converge in a lot fewer other iterations.

249
00:08:44,990 --> 00:08:46,070
That was feature scaling.

250
00:08:46,080 --> 00:08:47,340
In the next video, I'll tell

251
00:08:47,350 --> 00:08:49,700
you about another trick to make

252
00:08:49,710 --> 00:08:52,470
gradient descent work well in practice.

