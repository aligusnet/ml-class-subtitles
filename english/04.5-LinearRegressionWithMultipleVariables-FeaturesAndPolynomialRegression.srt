1
00:00:00,200 --> 00:00:03,900
You now know about linear regression with multiple variables.

2
00:00:03,910 --> 00:00:05,160
In this video, I wanna tell

3
00:00:05,170 --> 00:00:06,370
you a bit about the choice

4
00:00:06,380 --> 00:00:07,760
of features that you have and

5
00:00:07,770 --> 00:00:09,740
how you can get different learning

6
00:00:09,750 --> 00:00:11,460
out of them, sometimes very powerful

7
00:00:11,470 --> 00:00:13,800
ones by choosing appropriate features.

8
00:00:13,810 --> 00:00:15,200
And in particular I also want

9
00:00:15,210 --> 00:00:17,800
to tell you about polynomial regression allows

10
00:00:17,810 --> 00:00:19,490
you to use the machinery of

11
00:00:19,500 --> 00:00:21,220
linear regression to fit very

12
00:00:21,230 --> 00:00:24,760
complicated, even very non-linear functions.

13
00:00:25,690 --> 00:00:29,290
Let's take the example of predicting the price of the house.

14
00:00:29,300 --> 00:00:31,120
Suppose you have two features,

15
00:00:31,130 --> 00:00:33,760
the frontage of house and the depth of the house.

16
00:00:33,770 --> 00:00:35,380
So, here's the picture of the house we're trying to sell.

17
00:00:35,390 --> 00:00:37,230
So, the frontage is

18
00:00:37,240 --> 00:00:39,990
defined as this distance

19
00:00:40,380 --> 00:00:42,960
is basically the width

20
00:00:42,970 --> 00:00:44,950
or the length of

21
00:00:44,960 --> 00:00:46,630
how wide your lot

22
00:00:46,640 --> 00:00:48,010
is if this that you

23
00:00:48,020 --> 00:00:49,490
own, and the depth

24
00:00:49,500 --> 00:00:53,120
of the house is how

25
00:00:53,130 --> 00:00:54,760
deep your property is, so

26
00:00:54,770 --> 00:00:58,120
there's a frontage, there's a depth.

27
00:00:58,130 --> 00:00:59,810
called frontage and def.

28
00:00:59,820 --> 00:01:01,350
You might build a linear regression

29
00:01:01,360 --> 00:01:04,170
model like this where frontage

30
00:01:04,180 --> 00:01:06,020
is your first feature x1 and

31
00:01:06,030 --> 00:01:07,510
your def is your second

32
00:01:07,520 --> 00:01:10,130
feature x2, but when you're

33
00:01:10,140 --> 00:01:11,750
applying linear regression, you don't

34
00:01:11,760 --> 00:01:13,330
necessarily have to use

35
00:01:13,340 --> 00:01:16,600
just the features x1 and x2 that you're given.

36
00:01:16,610 --> 00:01:20,520
What you can do is actually create new features by yourself.

37
00:01:20,530 --> 00:01:21,700
So, if I want to predict

38
00:01:21,710 --> 00:01:22,860
the price of a house, what I

39
00:01:22,870 --> 00:01:24,840
might do instead is decide

40
00:01:24,850 --> 00:01:27,480
that what really determines

41
00:01:27,490 --> 00:01:29,090
the size of the house is

42
00:01:29,100 --> 00:01:32,180
the area or the land area that I own.

43
00:01:32,190 --> 00:01:33,370
So, I might create a new feature.

44
00:01:33,380 --> 00:01:34,580
I'm just gonna call this feature

45
00:01:34,590 --> 00:01:40,430
x which is frontage, times depth.

46
00:01:40,440 --> 00:01:42,370
This is a multiplication symbol.

47
00:01:42,380 --> 00:01:44,320
It's a frontage x depth because

48
00:01:44,330 --> 00:01:46,080
this is the land area

49
00:01:46,090 --> 00:01:47,930
that I own and I might

50
00:01:47,940 --> 00:01:50,700
then select my hypothesis

51
00:01:50,710 --> 00:01:53,340
as that using just

52
00:01:53,350 --> 00:01:54,760
one feature which is my

53
00:01:54,770 --> 00:01:57,570
land area, right?

54
00:01:57,580 --> 00:01:58,930
Because the area of a

55
00:01:58,940 --> 00:02:00,300
rectangle is you know,

56
00:02:00,310 --> 00:02:01,450
the product of the length

57
00:02:01,460 --> 00:02:03,760
of the size So, depending

58
00:02:03,770 --> 00:02:05,270
on what insight you might have

59
00:02:05,280 --> 00:02:07,480
into a particular problem, rather than

60
00:02:07,490 --> 00:02:09,610
just taking the features [xx]

61
00:02:09,620 --> 00:02:11,120
that we happen to have started

62
00:02:11,130 --> 00:02:13,450
off with, sometimes by defining

63
00:02:13,460 --> 00:02:16,780
new features you might actually get a better model.

64
00:02:16,790 --> 00:02:18,150
Closely related to the

65
00:02:18,160 --> 00:02:19,650
idea of choosing your features

66
00:02:19,660 --> 00:02:23,000
is this idea called polynomial regression.

67
00:02:23,010 --> 00:02:26,870
Let's say you have a housing price data set that looks like this.

68
00:02:26,880 --> 00:02:29,650
Then there are a few different models you might fit to this.

69
00:02:29,660 --> 00:02:32,590
One thing you could do is fit a quadratic model like this.

70
00:02:32,600 --> 00:02:35,570
It doesn't look like a straight line fits this data very well.

71
00:02:35,580 --> 00:02:36,740
So maybe you want to fit

72
00:02:36,750 --> 00:02:38,410
a quadratic model like this

73
00:02:38,420 --> 00:02:40,230
where you think the size, where

74
00:02:40,240 --> 00:02:42,010
you think the price is a quadratic

75
00:02:42,020 --> 00:02:43,960
function and maybe that'll

76
00:02:43,970 --> 00:02:45,010
give you, you know, a fit

77
00:02:45,020 --> 00:02:47,270
to the data that looks like that.

78
00:02:47,280 --> 00:02:48,560
But then you may decide that your

79
00:02:48,570 --> 00:02:50,000
quadratic model doesn't make sense

80
00:02:50,010 --> 00:02:52,560
because of a quadratic function, eventually

81
00:02:52,570 --> 00:02:53,830
this function comes back down

82
00:02:53,840 --> 00:02:55,590
and well, we don't think housing

83
00:02:55,600 --> 00:02:58,960
prices should go down when the size goes up too high.

84
00:02:58,970 --> 00:03:00,640
So then maybe we might

85
00:03:00,650 --> 00:03:02,680
choose a different polynomial model

86
00:03:02,690 --> 00:03:04,280
and choose to use instead a

87
00:03:04,290 --> 00:03:07,470
cubic function, and where

88
00:03:07,480 --> 00:03:09,200
we have now a third-order term

89
00:03:09,210 --> 00:03:10,790
and we fit that, maybe

90
00:03:10,800 --> 00:03:12,380
we get this sort of

91
00:03:12,390 --> 00:03:13,900
model, and maybe the

92
00:03:13,910 --> 00:03:15,210
green line is a somewhat better fit

93
00:03:15,220 --> 00:03:18,040
to the data cause it doesn't eventually come back down.

94
00:03:18,050 --> 00:03:22,010
So how do we actually fit a model like this to our data?

95
00:03:22,020 --> 00:03:23,680
Using the machinery of multivariant

96
00:03:23,690 --> 00:03:26,970
linear regression, we can

97
00:03:26,980 --> 00:03:30,680
do this with a pretty simple modification to our algorithm.

98
00:03:30,690 --> 00:03:32,620
The form of the hypothesis we,

99
00:03:32,630 --> 00:03:34,180
we know how the fit

100
00:03:34,190 --> 00:03:35,760
looks like this, where we say

101
00:03:35,770 --> 00:03:37,600
H of x is theta zero

102
00:03:37,610 --> 00:03:41,540
plus theta one x one plus x two theta X3.

103
00:03:41,550 --> 00:03:42,680
And if we want to

104
00:03:42,690 --> 00:03:45,240
fit this cubic model that

105
00:03:45,250 --> 00:03:47,190
I have boxed in green,

106
00:03:47,200 --> 00:03:48,920
what we're saying is that

107
00:03:48,930 --> 00:03:49,800
to predict the price of a

108
00:03:49,810 --> 00:03:51,340
house, it's theta 0 plus theta

109
00:03:51,350 --> 00:03:53,000
1 times the size of the house

110
00:03:53,010 --> 00:03:55,900
plus theta 2 times the square size of the house.

111
00:03:55,910 --> 00:03:58,950
So this term is equal to that term.

112
00:03:58,960 --> 00:04:00,880
And then plus theta 3

113
00:04:00,890 --> 00:04:02,340
times the cube of the

114
00:04:02,350 --> 00:04:05,460
size of the house raises that third term.

115
00:04:05,470 --> 00:04:06,980
In order to map these

116
00:04:06,990 --> 00:04:08,670
two definitions to each other,

117
00:04:08,680 --> 00:04:10,310
well, the natural way

118
00:04:10,320 --> 00:04:12,140
to do that is to set

119
00:04:12,150 --> 00:04:13,530
the first feature x one to

120
00:04:13,540 --> 00:04:15,300
be the size of the house, and

121
00:04:15,310 --> 00:04:16,670
set the second feature x two

122
00:04:16,680 --> 00:04:17,720
to be the square of the size

123
00:04:17,730 --> 00:04:20,330
of the house, and set the third feature x three to

124
00:04:20,340 --> 00:04:22,790
be the cube of the size of the house.

125
00:04:22,800 --> 00:04:24,270
And, just by choosing my

126
00:04:24,280 --> 00:04:26,290
three features this way and

127
00:04:26,300 --> 00:04:27,710
applying the machinery of linear

128
00:04:27,720 --> 00:04:30,470
regression, I can fit this

129
00:04:30,480 --> 00:04:31,880
model and end up with

130
00:04:31,890 --> 00:04:34,350
a cubic fit to my data.

131
00:04:34,360 --> 00:04:35,400
I just want to point out one

132
00:04:35,410 --> 00:04:36,790
more thing, which is that

133
00:04:36,800 --> 00:04:38,470
if you choose your features

134
00:04:38,480 --> 00:04:40,830
like this, then feature scaling

135
00:04:40,840 --> 00:04:43,450
becomes increasingly important.

136
00:04:44,130 --> 00:04:45,150
So if the size of the

137
00:04:45,160 --> 00:04:46,790
house ranges from one to

138
00:04:46,800 --> 00:04:47,890
a thousand, so, you know,

139
00:04:47,900 --> 00:04:49,300
from one to a thousand square

140
00:04:49,310 --> 00:04:50,920
feet, say, then the size

141
00:04:50,930 --> 00:04:52,150
squared of the house will

142
00:04:52,160 --> 00:04:54,510
range from one to one

143
00:04:54,520 --> 00:04:55,930
million, the square of

144
00:04:55,940 --> 00:04:58,480
a thousand, and your third

145
00:04:58,490 --> 00:05:01,350
feature x cubed, excuse me

146
00:05:01,360 --> 00:05:03,110
you, your third feature x

147
00:05:03,120 --> 00:05:04,700
three, which is the size

148
00:05:04,710 --> 00:05:05,940
cubed of the house, will range

149
00:05:05,950 --> 00:05:07,430
from one two ten to

150
00:05:07,440 --> 00:05:09,320
the nine, and so these

151
00:05:09,330 --> 00:05:10,850
three features take on very

152
00:05:10,860 --> 00:05:13,480
different ranges of values, and

153
00:05:13,490 --> 00:05:15,100
it's important to apply feature

154
00:05:15,110 --> 00:05:16,470
scaling if you're using gradient

155
00:05:16,480 --> 00:05:18,520
descent to get them into

156
00:05:18,530 --> 00:05:21,130
comparable ranges of values.

157
00:05:21,140 --> 00:05:23,240
Finally, here's one last example

158
00:05:23,250 --> 00:05:25,140
of how you really have

159
00:05:25,150 --> 00:05:29,080
broad choices in the features you use.

160
00:05:29,090 --> 00:05:30,430
Earlier we talked about how a

161
00:05:30,440 --> 00:05:31,510
quadratic model like this might

162
00:05:31,520 --> 00:05:33,040
not be ideal because, you know,

163
00:05:33,050 --> 00:05:34,360
maybe a quadratic model fits the

164
00:05:34,370 --> 00:05:35,930
data okay, but the quadratic

165
00:05:35,940 --> 00:05:37,470
function goes back down

166
00:05:37,480 --> 00:05:39,060
and we really don't want, right,

167
00:05:39,070 --> 00:05:40,320
housing prices that go down,

168
00:05:40,330 --> 00:05:43,550
to predict that, as the size of housing freezes.

169
00:05:43,560 --> 00:05:45,350
But rather than going to

170
00:05:45,360 --> 00:05:46,890
a cubic model there, you

171
00:05:46,900 --> 00:05:48,270
have, maybe, other choices of

172
00:05:48,280 --> 00:05:50,790
features and there are many possible choices.

173
00:05:50,800 --> 00:05:52,290
But just to give you another

174
00:05:52,300 --> 00:05:53,670
example of a reasonable

175
00:05:53,680 --> 00:05:55,600
choice, another reasonable choice

176
00:05:55,610 --> 00:05:57,250
might be to say that the

177
00:05:57,260 --> 00:05:58,840
price of a house is theta

178
00:05:58,850 --> 00:05:59,980
zero plus theta one times

179
00:05:59,990 --> 00:06:01,310
the size, and then plus theta

180
00:06:01,320 --> 00:06:03,620
two times the square root of the size, right?

181
00:06:03,630 --> 00:06:05,350
So the square root function is

182
00:06:05,360 --> 00:06:08,070
this sort of function, and maybe

183
00:06:08,080 --> 00:06:09,290
there will be some value of theta

184
00:06:09,300 --> 00:06:11,300
one, theta two, theta three, that

185
00:06:11,310 --> 00:06:14,070
will let you take this model

186
00:06:14,080 --> 00:06:15,420
and, for the curve that looks

187
00:06:15,430 --> 00:06:16,910
like that, and, you know,

188
00:06:16,920 --> 00:06:19,510
goes up, but sort of flattens

189
00:06:19,520 --> 00:06:21,530
out a bit and doesn't ever

190
00:06:21,540 --> 00:06:24,320
come back down.

191
00:06:24,330 --> 00:06:26,550
And, so, by having insight into, in

192
00:06:26,560 --> 00:06:27,580
this case, the shape of a

193
00:06:27,590 --> 00:06:30,980
square root function, and, into

194
00:06:30,990 --> 00:06:32,540
the shape of the data, by choosing

195
00:06:32,550 --> 00:06:36,260
different features, you can sometimes get better models.

196
00:06:37,300 --> 00:06:40,370
In this video, we talked about polynomial regression.

197
00:06:40,380 --> 00:06:41,770
That is, how to fit a

198
00:06:41,780 --> 00:06:43,350
polynomial, like a quadratic function,

199
00:06:43,360 --> 00:06:45,350
or a cubic function, to your data.

200
00:06:45,360 --> 00:06:46,410
Was also throw out this idea,

201
00:06:46,420 --> 00:06:47,630
that you have a choice in what

202
00:06:47,640 --> 00:06:48,800
features to use, such as

203
00:06:48,810 --> 00:06:50,240
that instead of using

204
00:06:50,250 --> 00:06:51,530
the frontish and the depth

205
00:06:51,540 --> 00:06:52,590
of the house, maybe, you can

206
00:06:52,600 --> 00:06:54,400
multiply them together to get

207
00:06:54,410 --> 00:06:57,830
a feature that captures the land area of a house.

208
00:06:57,840 --> 00:06:59,110
In case this seems a little

209
00:06:59,120 --> 00:07:01,040
bit bewildering, that with all

210
00:07:01,050 --> 00:07:04,670
these different feature choices, so how do I decide what features to use.

211
00:07:04,680 --> 00:07:05,830
Later in this class, we'll talk

212
00:07:05,840 --> 00:07:07,950
about some algorithms were automatically

213
00:07:07,960 --> 00:07:09,350
choosing what features are used,

214
00:07:09,360 --> 00:07:10,610
so you can have an

215
00:07:10,620 --> 00:07:11,970
algorithm look at the data

216
00:07:11,980 --> 00:07:13,830
and automatically choose for you

217
00:07:13,840 --> 00:07:14,870
whether you want to fit a

218
00:07:14,880 --> 00:07:17,800
quadratic function, or a cubic function, or something else.

219
00:07:17,810 --> 00:07:18,800
But, until we get to

220
00:07:18,810 --> 00:07:20,400
those algorithms now I just

221
00:07:20,410 --> 00:07:21,700
want you to be aware that

222
00:07:21,710 --> 00:07:23,080
you have a choice in

223
00:07:23,090 --> 00:07:24,730
what features to use, and

224
00:07:24,740 --> 00:07:26,600
by designing different features

225
00:07:26,610 --> 00:07:28,170
you can fit more complex functions

226
00:07:28,180 --> 00:07:29,700
your data then just fitting a

227
00:07:29,710 --> 00:07:31,830
straight line to the data and

228
00:07:31,840 --> 00:07:33,390
in particular you can put polynomial

229
00:07:33,400 --> 00:07:35,870
functions as well and sometimes

230
00:07:35,880 --> 00:07:37,400
by appropriate insight into the

231
00:07:37,410 --> 00:07:38,600
feature simply get a much

232
00:07:38,610 --> 00:07:41,520
better model for your data.

